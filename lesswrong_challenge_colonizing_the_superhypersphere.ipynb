{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8n_vM3jIitW"
      },
      "source": [
        "# lesswrong challenge: Colonizing the SuperHyperSphere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3fu4tcIgHF"
      },
      "source": [
        "problem: https://www.lesswrong.com/posts/Rpjrwspx2QZuHbmPE/d-and-d-sci-fi-colonizing-the-superhypersphere-evaluation\n",
        "\n",
        "submit: https://h-b-p.github.io/d-and-d-sci-SuperHyperSphere/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aktjQ_0E0BWR"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOkR7Lp1B_6b",
        "outputId": "acc75e28-97a4-4b55-f703-703fc4e8c5bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/sfgeekgit/lesswrongDataDzppg/main/cleared_sites_formated.csv\n",
        "!wget https://raw.githubusercontent.com/sfgeekgit/lesswrongDataDzppg/main/measured_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "82HUMHLYzpwS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KQTuTq9u_WBQ"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "unlabeled = pd.read_csv('cleared_sites_formated.csv')\n",
        "labeled = pd.read_csv('measured_data.csv')\n",
        "n_features = labeled.shape[1] - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKtElfWrAiqi",
        "outputId": "d5b29791-b579-4255-ac9e-f88c555a8e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data: 9366\n",
            "test data:  1041\n"
          ]
        }
      ],
      "source": [
        "# split into training and test sets\n",
        "train_data2, test_data = train_test_split(labeled, test_size =.1, random_state = 1)\n",
        "train_labels = train_data2['ZPPG_Performance']\n",
        "train_data = train_data2.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "\n",
        "print(f'train data: {len(train_data)}')\n",
        "print(f'test data:  {len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RtIRD5cz948"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4_e6yDO-PVLk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, dataset):\n",
        "  model.eval()\n",
        "  val = dataset.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "  preds = model(torch.tensor(val.values).float().to(device))\n",
        "  labels = torch.tensor(dataset['ZPPG_Performance'].values).view(-1, 1).to(device)\n",
        "  diff = preds.detach() - labels\n",
        "  error = diff.abs().mean().item()\n",
        "  model.train()\n",
        "  return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "90VqjJY46_3T"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def topn(model, dataset, n=15):\n",
        "  model.eval()\n",
        "  to_drop = ['ZPPG_id']\n",
        "  if 'ZPPG_Performance' in dataset: to_drop.append('ZPPG_Performance')\n",
        "  preds = model(torch.tensor(dataset.drop(to_drop, axis=1).values).float().to(device))\n",
        "  ids = dataset['ZPPG_id']\n",
        "  preds_id = list(zip(\n",
        "    preds.view(-1).tolist(),\n",
        "    ids.values.tolist()))\n",
        "  return sorted(preds_id, reverse=True)[:n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PS_EWz00EXo"
      },
      "source": [
        "## model and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "eWGrZfBgAjlJ"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_inputs=n_features, hidden=64, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(n_inputs, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, 1),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6ba5xzovGe0u"
      },
      "outputs": [],
      "source": [
        "model = MLP().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAdJbaa_AuQ-",
        "outputId": "9180ac60-273b-4a86-d04b-6e0fca155b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=    0 loss.item()= 0.2941 error_test= 0.2569 error_train= 0.2569\n",
            "epoch=  200 loss.item()= 0.0422 error_test= 0.1328 error_train= 0.1328\n",
            "epoch=  400 loss.item()= 0.0337 error_test= 0.1315 error_train= 0.1315\n",
            "epoch=  600 loss.item()= 0.0309 error_test= 0.1297 error_train= 0.1297\n",
            "epoch=  800 loss.item()= 0.0295 error_test= 0.1264 error_train= 0.1264\n",
            "epoch= 1000 loss.item()= 0.0223 error_test= 0.0931 error_train= 0.0931\n",
            "epoch= 1200 loss.item()= 0.0159 error_test= 0.0738 error_train= 0.0738\n",
            "epoch= 1400 loss.item()= 0.0124 error_test= 0.0647 error_train= 0.0647\n",
            "epoch= 1600 loss.item()= 0.0100 error_test= 0.0599 error_train= 0.0599\n",
            "epoch= 1800 loss.item()= 0.0085 error_test= 0.0538 error_train= 0.0538\n",
            "epoch= 2000 loss.item()= 0.0072 error_test= 0.0500 error_train= 0.0500\n",
            "epoch= 2200 loss.item()= 0.0066 error_test= 0.0491 error_train= 0.0491\n",
            "epoch= 2400 loss.item()= 0.0059 error_test= 0.0481 error_train= 0.0481\n",
            "epoch= 2600 loss.item()= 0.0058 error_test= 0.0482 error_train= 0.0482\n",
            "epoch= 2800 loss.item()= 0.0053 error_test= 0.0472 error_train= 0.0472\n",
            "epoch= 3000 loss.item()= 0.0050 error_test= 0.0478 error_train= 0.0478\n",
            "epoch= 3200 loss.item()= 0.0046 error_test= 0.0467 error_train= 0.0467\n",
            "epoch= 3400 loss.item()= 0.0043 error_test= 0.0465 error_train= 0.0465\n",
            "epoch= 3600 loss.item()= 0.0039 error_test= 0.0463 error_train= 0.0463\n",
            "epoch= 3800 loss.item()= 0.0039 error_test= 0.0461 error_train= 0.0461\n",
            "epoch= 4000 loss.item()= 0.0037 error_test= 0.0449 error_train= 0.0449\n",
            "epoch= 4200 loss.item()= 0.0034 error_test= 0.0454 error_train= 0.0454\n",
            "epoch= 4400 loss.item()= 0.0034 error_test= 0.0444 error_train= 0.0444\n",
            "epoch= 4600 loss.item()= 0.0034 error_test= 0.0445 error_train= 0.0445\n",
            "epoch= 4800 loss.item()= 0.0032 error_test= 0.0449 error_train= 0.0449\n",
            "epoch= 5000 loss.item()= 0.0031 error_test= 0.0447 error_train= 0.0447\n",
            "epoch= 5200 loss.item()= 0.0028 error_test= 0.0441 error_train= 0.0441\n",
            "epoch= 5400 loss.item()= 0.0027 error_test= 0.0436 error_train= 0.0436\n",
            "epoch= 5600 loss.item()= 0.0027 error_test= 0.0426 error_train= 0.0426\n",
            "epoch= 5800 loss.item()= 0.0026 error_test= 0.0427 error_train= 0.0427\n",
            "epoch= 6000 loss.item()= 0.0023 error_test= 0.0436 error_train= 0.0436\n",
            "epoch= 6200 loss.item()= 0.0023 error_test= 0.0425 error_train= 0.0425\n",
            "epoch= 6400 loss.item()= 0.0023 error_test= 0.0430 error_train= 0.0430\n",
            "epoch= 6600 loss.item()= 0.0022 error_test= 0.0442 error_train= 0.0442\n",
            "epoch= 6800 loss.item()= 0.0022 error_test= 0.0433 error_train= 0.0433\n",
            "epoch= 7000 loss.item()= 0.0022 error_test= 0.0439 error_train= 0.0439\n",
            "epoch= 7200 loss.item()= 0.0021 error_test= 0.0441 error_train= 0.0441\n",
            "epoch= 7400 loss.item()= 0.0020 error_test= 0.0435 error_train= 0.0435\n",
            "epoch= 7600 loss.item()= 0.0020 error_test= 0.0448 error_train= 0.0448\n",
            "epoch= 7800 loss.item()= 0.0020 error_test= 0.0443 error_train= 0.0443\n",
            "epoch= 8000 loss.item()= 0.0020 error_test= 0.0454 error_train= 0.0454\n",
            "epoch= 8200 loss.item()= 0.0019 error_test= 0.0439 error_train= 0.0439\n",
            "epoch= 8400 loss.item()= 0.0018 error_test= 0.0448 error_train= 0.0448\n",
            "epoch= 8600 loss.item()= 0.0018 error_test= 0.0448 error_train= 0.0448\n",
            "epoch= 8800 loss.item()= 0.0017 error_test= 0.0452 error_train= 0.0452\n",
            "epoch= 9000 loss.item()= 0.0018 error_test= 0.0450 error_train= 0.0450\n",
            "epoch= 9200 loss.item()= 0.0017 error_test= 0.0441 error_train= 0.0441\n",
            "epoch= 9400 loss.item()= 0.0017 error_test= 0.0437 error_train= 0.0437\n",
            "epoch= 9600 loss.item()= 0.0017 error_test= 0.0446 error_train= 0.0446\n",
            "epoch= 9800 loss.item()= 0.0017 error_test= 0.0448 error_train= 0.0448\n",
            "epoch=10000 loss.item()= 0.0016 error_test= 0.0442 error_train= 0.0442\n",
            "epoch=10200 loss.item()= 0.0015 error_test= 0.0444 error_train= 0.0444\n",
            "epoch=10400 loss.item()= 0.0014 error_test= 0.0441 error_train= 0.0441\n",
            "epoch=10600 loss.item()= 0.0014 error_test= 0.0447 error_train= 0.0447\n",
            "epoch=10800 loss.item()= 0.0013 error_test= 0.0442 error_train= 0.0442\n",
            "epoch=11000 loss.item()= 0.0013 error_test= 0.0453 error_train= 0.0453\n",
            "epoch=11200 loss.item()= 0.0013 error_test= 0.0451 error_train= 0.0451\n",
            "epoch=11400 loss.item()= 0.0012 error_test= 0.0448 error_train= 0.0448\n",
            "epoch=11600 loss.item()= 0.0012 error_test= 0.0449 error_train= 0.0449\n",
            "epoch=11800 loss.item()= 0.0012 error_test= 0.0443 error_train= 0.0443\n",
            "epoch=12000 loss.item()= 0.0011 error_test= 0.0452 error_train= 0.0452\n",
            "epoch=12200 loss.item()= 0.0011 error_test= 0.0454 error_train= 0.0454\n",
            "epoch=12400 loss.item()= 0.0011 error_test= 0.0440 error_train= 0.0440\n",
            "epoch=12600 loss.item()= 0.0011 error_test= 0.0452 error_train= 0.0452\n",
            "epoch=12800 loss.item()= 0.0010 error_test= 0.0458 error_train= 0.0458\n",
            "epoch=13000 loss.item()= 0.0010 error_test= 0.0466 error_train= 0.0466\n",
            "epoch=13200 loss.item()= 0.0010 error_test= 0.0462 error_train= 0.0462\n",
            "epoch=13400 loss.item()= 0.0010 error_test= 0.0457 error_train= 0.0457\n",
            "epoch=13600 loss.item()= 0.0011 error_test= 0.0475 error_train= 0.0475\n",
            "epoch=13800 loss.item()= 0.0010 error_test= 0.0465 error_train= 0.0465\n",
            "epoch=14000 loss.item()= 0.0010 error_test= 0.0468 error_train= 0.0468\n",
            "epoch=14200 loss.item()= 0.0010 error_test= 0.0463 error_train= 0.0463\n",
            "epoch=14400 loss.item()= 0.0010 error_test= 0.0465 error_train= 0.0465\n",
            "epoch=14600 loss.item()= 0.0010 error_test= 0.0461 error_train= 0.0461\n",
            "epoch=14800 loss.item()= 0.0010 error_test= 0.0468 error_train= 0.0468\n",
            "epoch=15000 loss.item()= 0.0010 error_test= 0.0470 error_train= 0.0470\n",
            "epoch=15200 loss.item()= 0.0009 error_test= 0.0474 error_train= 0.0474\n",
            "epoch=15400 loss.item()= 0.0008 error_test= 0.0463 error_train= 0.0463\n",
            "epoch=15600 loss.item()= 0.0008 error_test= 0.0483 error_train= 0.0483\n",
            "epoch=15800 loss.item()= 0.0008 error_test= 0.0490 error_train= 0.0490\n",
            "epoch=16000 loss.item()= 0.0008 error_test= 0.0480 error_train= 0.0480\n",
            "epoch=16200 loss.item()= 0.0008 error_test= 0.0487 error_train= 0.0487\n",
            "epoch=16400 loss.item()= 0.0008 error_test= 0.0493 error_train= 0.0493\n",
            "epoch=16600 loss.item()= 0.0008 error_test= 0.0491 error_train= 0.0491\n",
            "epoch=16800 loss.item()= 0.0008 error_test= 0.0499 error_train= 0.0499\n",
            "epoch=17000 loss.item()= 0.0008 error_test= 0.0497 error_train= 0.0497\n",
            "epoch=17200 loss.item()= 0.0008 error_test= 0.0490 error_train= 0.0490\n",
            "epoch=17400 loss.item()= 0.0008 error_test= 0.0500 error_train= 0.0500\n",
            "epoch=17600 loss.item()= 0.0008 error_test= 0.0490 error_train= 0.0490\n",
            "epoch=17800 loss.item()= 0.0008 error_test= 0.0494 error_train= 0.0494\n",
            "epoch=18000 loss.item()= 0.0007 error_test= 0.0503 error_train= 0.0503\n",
            "epoch=18200 loss.item()= 0.0008 error_test= 0.0501 error_train= 0.0501\n",
            "epoch=18400 loss.item()= 0.0007 error_test= 0.0498 error_train= 0.0498\n",
            "epoch=18600 loss.item()= 0.0008 error_test= 0.0504 error_train= 0.0504\n",
            "epoch=18800 loss.item()= 0.0008 error_test= 0.0501 error_train= 0.0501\n",
            "epoch=19000 loss.item()= 0.0008 error_test= 0.0496 error_train= 0.0496\n",
            "epoch=19200 loss.item()= 0.0008 error_test= 0.0503 error_train= 0.0503\n",
            "epoch=19400 loss.item()= 0.0007 error_test= 0.0501 error_train= 0.0501\n",
            "epoch=19600 loss.item()= 0.0007 error_test= 0.0500 error_train= 0.0500\n",
            "epoch=19800 loss.item()= 0.0007 error_test= 0.0500 error_train= 0.0500\n",
            "epoch=20000 loss.item()= 0.0007 error_test= 0.0509 error_train= 0.0509\n",
            "epoch=20200 loss.item()= 0.0006 error_test= 0.0494 error_train= 0.0494\n",
            "epoch=20400 loss.item()= 0.0007 error_test= 0.0507 error_train= 0.0507\n",
            "epoch=20600 loss.item()= 0.0008 error_test= 0.0513 error_train= 0.0513\n",
            "epoch=20800 loss.item()= 0.0007 error_test= 0.0514 error_train= 0.0514\n",
            "epoch=21000 loss.item()= 0.0007 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=21200 loss.item()= 0.0007 error_test= 0.0505 error_train= 0.0505\n",
            "epoch=21400 loss.item()= 0.0007 error_test= 0.0510 error_train= 0.0510\n",
            "epoch=21600 loss.item()= 0.0007 error_test= 0.0509 error_train= 0.0509\n",
            "epoch=21800 loss.item()= 0.0007 error_test= 0.0508 error_train= 0.0508\n",
            "epoch=22000 loss.item()= 0.0007 error_test= 0.0515 error_train= 0.0515\n",
            "epoch=22200 loss.item()= 0.0007 error_test= 0.0511 error_train= 0.0511\n",
            "epoch=22400 loss.item()= 0.0007 error_test= 0.0513 error_train= 0.0513\n",
            "epoch=22600 loss.item()= 0.0006 error_test= 0.0509 error_train= 0.0509\n",
            "epoch=22800 loss.item()= 0.0007 error_test= 0.0516 error_train= 0.0516\n",
            "epoch=23000 loss.item()= 0.0007 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=23200 loss.item()= 0.0007 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=23400 loss.item()= 0.0006 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=23600 loss.item()= 0.0006 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=23800 loss.item()= 0.0007 error_test= 0.0523 error_train= 0.0523\n",
            "epoch=24000 loss.item()= 0.0007 error_test= 0.0511 error_train= 0.0511\n",
            "epoch=24200 loss.item()= 0.0006 error_test= 0.0515 error_train= 0.0515\n",
            "epoch=24400 loss.item()= 0.0006 error_test= 0.0507 error_train= 0.0507\n",
            "epoch=24600 loss.item()= 0.0006 error_test= 0.0522 error_train= 0.0522\n",
            "epoch=24800 loss.item()= 0.0006 error_test= 0.0510 error_train= 0.0510\n",
            "epoch=25000 loss.item()= 0.0007 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=25200 loss.item()= 0.0006 error_test= 0.0515 error_train= 0.0515\n",
            "epoch=25400 loss.item()= 0.0007 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=25600 loss.item()= 0.0006 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=25800 loss.item()= 0.0006 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=26000 loss.item()= 0.0007 error_test= 0.0516 error_train= 0.0516\n",
            "epoch=26200 loss.item()= 0.0006 error_test= 0.0514 error_train= 0.0514\n",
            "epoch=26400 loss.item()= 0.0006 error_test= 0.0508 error_train= 0.0508\n",
            "epoch=26600 loss.item()= 0.0007 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=26800 loss.item()= 0.0006 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=27000 loss.item()= 0.0006 error_test= 0.0510 error_train= 0.0510\n",
            "epoch=27200 loss.item()= 0.0007 error_test= 0.0521 error_train= 0.0521\n",
            "epoch=27400 loss.item()= 0.0007 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=27600 loss.item()= 0.0006 error_test= 0.0511 error_train= 0.0511\n",
            "epoch=27800 loss.item()= 0.0006 error_test= 0.0520 error_train= 0.0520\n",
            "epoch=28000 loss.item()= 0.0006 error_test= 0.0518 error_train= 0.0518\n",
            "epoch=28200 loss.item()= 0.0006 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=28400 loss.item()= 0.0006 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=28600 loss.item()= 0.0006 error_test= 0.0514 error_train= 0.0514\n",
            "epoch=28800 loss.item()= 0.0007 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=29000 loss.item()= 0.0006 error_test= 0.0512 error_train= 0.0512\n",
            "epoch=29200 loss.item()= 0.0006 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=29400 loss.item()= 0.0006 error_test= 0.0510 error_train= 0.0510\n",
            "epoch=29600 loss.item()= 0.0006 error_test= 0.0511 error_train= 0.0511\n",
            "epoch=29800 loss.item()= 0.0006 error_test= 0.0518 error_train= 0.0518\n",
            "epoch=30000 loss.item()= 0.0006 error_test= 0.0513 error_train= 0.0513\n",
            "epoch=30200 loss.item()= 0.0006 error_test= 0.0513 error_train= 0.0513\n",
            "epoch=30400 loss.item()= 0.0006 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=30600 loss.item()= 0.0006 error_test= 0.0517 error_train= 0.0517\n",
            "epoch=30800 loss.item()= 0.0006 error_test= 0.0524 error_train= 0.0524\n",
            "epoch=31000 loss.item()= 0.0006 error_test= 0.0520 error_train= 0.0520\n",
            "epoch=31200 loss.item()= 0.0006 error_test= 0.0525 error_train= 0.0525\n",
            "epoch=31400 loss.item()= 0.0006 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=31600 loss.item()= 0.0006 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=31800 loss.item()= 0.0006 error_test= 0.0520 error_train= 0.0520\n",
            "epoch=32000 loss.item()= 0.0006 error_test= 0.0518 error_train= 0.0518\n",
            "epoch=32200 loss.item()= 0.0006 error_test= 0.0522 error_train= 0.0522\n",
            "epoch=32400 loss.item()= 0.0006 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=32600 loss.item()= 0.0006 error_test= 0.0520 error_train= 0.0520\n",
            "epoch=32800 loss.item()= 0.0006 error_test= 0.0521 error_train= 0.0521\n",
            "epoch=33000 loss.item()= 0.0006 error_test= 0.0522 error_train= 0.0522\n",
            "epoch=33200 loss.item()= 0.0006 error_test= 0.0524 error_train= 0.0524\n",
            "epoch=33400 loss.item()= 0.0006 error_test= 0.0519 error_train= 0.0519\n",
            "epoch=33600 loss.item()= 0.0006 error_test= 0.0523 error_train= 0.0523\n",
            "epoch=33800 loss.item()= 0.0006 error_test= 0.0521 error_train= 0.0521\n",
            "epoch=34000 loss.item()= 0.0005 error_test= 0.0528 error_train= 0.0528\n",
            "epoch=34200 loss.item()= 0.0006 error_test= 0.0524 error_train= 0.0524\n",
            "epoch=34400 loss.item()= 0.0006 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=34600 loss.item()= 0.0006 error_test= 0.0518 error_train= 0.0518\n",
            "epoch=34800 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=35000 loss.item()= 0.0006 error_test= 0.0531 error_train= 0.0531\n",
            "epoch=35200 loss.item()= 0.0006 error_test= 0.0530 error_train= 0.0530\n",
            "epoch=35400 loss.item()= 0.0006 error_test= 0.0526 error_train= 0.0526\n",
            "epoch=35600 loss.item()= 0.0006 error_test= 0.0530 error_train= 0.0530\n",
            "epoch=35800 loss.item()= 0.0005 error_test= 0.0529 error_train= 0.0529\n",
            "epoch=36000 loss.item()= 0.0006 error_test= 0.0532 error_train= 0.0532\n",
            "epoch=36200 loss.item()= 0.0006 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=36400 loss.item()= 0.0006 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=36600 loss.item()= 0.0005 error_test= 0.0524 error_train= 0.0524\n",
            "epoch=36800 loss.item()= 0.0005 error_test= 0.0524 error_train= 0.0524\n",
            "epoch=37000 loss.item()= 0.0006 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=37200 loss.item()= 0.0006 error_test= 0.0529 error_train= 0.0529\n",
            "epoch=37400 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=37600 loss.item()= 0.0005 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=37800 loss.item()= 0.0006 error_test= 0.0520 error_train= 0.0520\n",
            "epoch=38000 loss.item()= 0.0006 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=38200 loss.item()= 0.0005 error_test= 0.0531 error_train= 0.0531\n",
            "epoch=38400 loss.item()= 0.0006 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=38600 loss.item()= 0.0005 error_test= 0.0530 error_train= 0.0530\n",
            "epoch=38800 loss.item()= 0.0006 error_test= 0.0531 error_train= 0.0531\n",
            "epoch=39000 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=39200 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=39400 loss.item()= 0.0005 error_test= 0.0530 error_train= 0.0530\n",
            "epoch=39600 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=39800 loss.item()= 0.0005 error_test= 0.0529 error_train= 0.0529\n",
            "epoch=40000 loss.item()= 0.0005 error_test= 0.0532 error_train= 0.0532\n",
            "epoch=40200 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=40400 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=40600 loss.item()= 0.0005 error_test= 0.0529 error_train= 0.0529\n",
            "epoch=40800 loss.item()= 0.0005 error_test= 0.0531 error_train= 0.0531\n",
            "epoch=41000 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=41200 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=41400 loss.item()= 0.0006 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=41600 loss.item()= 0.0005 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=41800 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=42000 loss.item()= 0.0005 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=42200 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=42400 loss.item()= 0.0005 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=42600 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=42800 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=43000 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=43200 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=43400 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=43600 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=43800 loss.item()= 0.0005 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=44000 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=44200 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=44400 loss.item()= 0.0005 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=44600 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=44800 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=45000 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=45200 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=45400 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=45600 loss.item()= 0.0005 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=45800 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=46000 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=46200 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=46400 loss.item()= 0.0005 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=46600 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=46800 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=47000 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=47200 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=47400 loss.item()= 0.0005 error_test= 0.0526 error_train= 0.0526\n",
            "epoch=47600 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=47800 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=48000 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=48200 loss.item()= 0.0005 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=48400 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=48600 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=48800 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=49000 loss.item()= 0.0005 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=49200 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=49400 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=49600 loss.item()= 0.0005 error_test= 0.0548 error_train= 0.0548\n",
            "epoch=49800 loss.item()= 0.0005 error_test= 0.0531 error_train= 0.0531\n",
            "epoch=50000 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=50200 loss.item()= 0.0005 error_test= 0.0546 error_train= 0.0546\n",
            "epoch=50400 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=50600 loss.item()= 0.0005 error_test= 0.0550 error_train= 0.0550\n",
            "epoch=50800 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=51000 loss.item()= 0.0005 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=51200 loss.item()= 0.0005 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=51400 loss.item()= 0.0005 error_test= 0.0549 error_train= 0.0549\n",
            "epoch=51600 loss.item()= 0.0005 error_test= 0.0546 error_train= 0.0546\n",
            "epoch=51800 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=52000 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=52200 loss.item()= 0.0005 error_test= 0.0548 error_train= 0.0548\n",
            "epoch=52400 loss.item()= 0.0005 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=52600 loss.item()= 0.0005 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=52800 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=53000 loss.item()= 0.0005 error_test= 0.0546 error_train= 0.0546\n",
            "epoch=53200 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=53400 loss.item()= 0.0005 error_test= 0.0549 error_train= 0.0549\n",
            "epoch=53600 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=53800 loss.item()= 0.0005 error_test= 0.0549 error_train= 0.0549\n",
            "epoch=54000 loss.item()= 0.0005 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=54200 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=54400 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=54600 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=54800 loss.item()= 0.0005 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=55000 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=55200 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=55400 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=55600 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=55800 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=56000 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=56200 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=56400 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=56600 loss.item()= 0.0004 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=56800 loss.item()= 0.0005 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=57000 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=57200 loss.item()= 0.0005 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=57400 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=57600 loss.item()= 0.0005 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=57800 loss.item()= 0.0004 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=58000 loss.item()= 0.0004 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=58200 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=58400 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=58600 loss.item()= 0.0004 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=58800 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=59000 loss.item()= 0.0004 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=59200 loss.item()= 0.0005 error_test= 0.0539 error_train= 0.0539\n",
            "epoch=59400 loss.item()= 0.0005 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=59600 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=59800 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=60000 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=60200 loss.item()= 0.0004 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=60400 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=60600 loss.item()= 0.0005 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=60800 loss.item()= 0.0004 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=61000 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=61200 loss.item()= 0.0004 error_test= 0.0536 error_train= 0.0536\n",
            "epoch=61400 loss.item()= 0.0004 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=61600 loss.item()= 0.0005 error_test= 0.0532 error_train= 0.0532\n",
            "epoch=61800 loss.item()= 0.0004 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=62000 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=62200 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=62400 loss.item()= 0.0005 error_test= 0.0537 error_train= 0.0537\n",
            "epoch=62600 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=62800 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=63000 loss.item()= 0.0005 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=63200 loss.item()= 0.0004 error_test= 0.0534 error_train= 0.0534\n",
            "epoch=63400 loss.item()= 0.0005 error_test= 0.0532 error_train= 0.0532\n",
            "epoch=63600 loss.item()= 0.0004 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=63800 loss.item()= 0.0005 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=64000 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=64200 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=64400 loss.item()= 0.0004 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=64600 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=64800 loss.item()= 0.0005 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=65000 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=65200 loss.item()= 0.0004 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=65400 loss.item()= 0.0005 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=65600 loss.item()= 0.0005 error_test= 0.0548 error_train= 0.0548\n",
            "epoch=65800 loss.item()= 0.0005 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=66000 loss.item()= 0.0004 error_test= 0.0546 error_train= 0.0546\n",
            "epoch=66200 loss.item()= 0.0005 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=66400 loss.item()= 0.0004 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=66600 loss.item()= 0.0004 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=66800 loss.item()= 0.0005 error_test= 0.0546 error_train= 0.0546\n",
            "epoch=67000 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=67200 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=67400 loss.item()= 0.0004 error_test= 0.0535 error_train= 0.0535\n",
            "epoch=67600 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=67800 loss.item()= 0.0004 error_test= 0.0538 error_train= 0.0538\n",
            "epoch=68000 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=68200 loss.item()= 0.0004 error_test= 0.0533 error_train= 0.0533\n",
            "epoch=68400 loss.item()= 0.0005 error_test= 0.0543 error_train= 0.0543\n",
            "epoch=68600 loss.item()= 0.0005 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=68800 loss.item()= 0.0004 error_test= 0.0540 error_train= 0.0540\n",
            "epoch=69000 loss.item()= 0.0005 error_test= 0.0542 error_train= 0.0542\n",
            "epoch=69200 loss.item()= 0.0005 error_test= 0.0551 error_train= 0.0551\n",
            "epoch=69400 loss.item()= 0.0004 error_test= 0.0541 error_train= 0.0541\n",
            "epoch=69600 loss.item()= 0.0004 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=69800 loss.item()= 0.0004 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=70000 loss.item()= 0.0004 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=70200 loss.item()= 0.0004 error_test= 0.0544 error_train= 0.0544\n",
            "epoch=70400 loss.item()= 0.0004 error_test= 0.0550 error_train= 0.0550\n",
            "epoch=70600 loss.item()= 0.0004 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=70800 loss.item()= 0.0004 error_test= 0.0545 error_train= 0.0545\n",
            "epoch=71000 loss.item()= 0.0005 error_test= 0.0546 error_train= 0.0546\n",
            "epoch=71200 loss.item()= 0.0004 error_test= 0.0550 error_train= 0.0550\n",
            "epoch=71400 loss.item()= 0.0004 error_test= 0.0553 error_train= 0.0553\n",
            "epoch=71600 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=71800 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=72000 loss.item()= 0.0004 error_test= 0.0554 error_train= 0.0554\n",
            "epoch=72200 loss.item()= 0.0005 error_test= 0.0550 error_train= 0.0550\n",
            "epoch=72400 loss.item()= 0.0004 error_test= 0.0554 error_train= 0.0554\n",
            "epoch=72600 loss.item()= 0.0004 error_test= 0.0554 error_train= 0.0554\n",
            "epoch=72800 loss.item()= 0.0004 error_test= 0.0547 error_train= 0.0547\n",
            "epoch=73000 loss.item()= 0.0004 error_test= 0.0560 error_train= 0.0560\n",
            "epoch=73200 loss.item()= 0.0004 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=73400 loss.item()= 0.0005 error_test= 0.0560 error_train= 0.0560\n",
            "epoch=73600 loss.item()= 0.0005 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=73800 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=74000 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=74200 loss.item()= 0.0004 error_test= 0.0549 error_train= 0.0549\n",
            "epoch=74400 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=74600 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=74800 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=75000 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=75200 loss.item()= 0.0004 error_test= 0.0551 error_train= 0.0551\n",
            "epoch=75400 loss.item()= 0.0004 error_test= 0.0557 error_train= 0.0557\n",
            "epoch=75600 loss.item()= 0.0004 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=75800 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=76000 loss.item()= 0.0004 error_test= 0.0558 error_train= 0.0558\n",
            "epoch=76200 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=76400 loss.item()= 0.0004 error_test= 0.0550 error_train= 0.0550\n",
            "epoch=76600 loss.item()= 0.0004 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=76800 loss.item()= 0.0004 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=77000 loss.item()= 0.0005 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=77200 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=77400 loss.item()= 0.0004 error_test= 0.0558 error_train= 0.0558\n",
            "epoch=77600 loss.item()= 0.0004 error_test= 0.0560 error_train= 0.0560\n",
            "epoch=77800 loss.item()= 0.0005 error_test= 0.0566 error_train= 0.0566\n",
            "epoch=78000 loss.item()= 0.0004 error_test= 0.0560 error_train= 0.0560\n",
            "epoch=78200 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=78400 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=78600 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=78800 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=79000 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=79200 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=79400 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=79600 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=79800 loss.item()= 0.0004 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=80000 loss.item()= 0.0004 error_test= 0.0555 error_train= 0.0555\n",
            "epoch=80200 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=80400 loss.item()= 0.0004 error_test= 0.0558 error_train= 0.0558\n",
            "epoch=80600 loss.item()= 0.0004 error_test= 0.0554 error_train= 0.0554\n",
            "epoch=80800 loss.item()= 0.0004 error_test= 0.0554 error_train= 0.0554\n",
            "epoch=81000 loss.item()= 0.0004 error_test= 0.0572 error_train= 0.0572\n",
            "epoch=81200 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=81400 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=81600 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=81800 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=82000 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=82200 loss.item()= 0.0004 error_test= 0.0560 error_train= 0.0560\n",
            "epoch=82400 loss.item()= 0.0004 error_test= 0.0560 error_train= 0.0560\n",
            "epoch=82600 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=82800 loss.item()= 0.0004 error_test= 0.0558 error_train= 0.0558\n",
            "epoch=83000 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=83200 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=83400 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=83600 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=83800 loss.item()= 0.0004 error_test= 0.0571 error_train= 0.0571\n",
            "epoch=84000 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=84200 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=84400 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=84600 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=84800 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=85000 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=85200 loss.item()= 0.0004 error_test= 0.0556 error_train= 0.0556\n",
            "epoch=85400 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=85600 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=85800 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=86000 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=86200 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=86400 loss.item()= 0.0004 error_test= 0.0571 error_train= 0.0571\n",
            "epoch=86600 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=86800 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=87000 loss.item()= 0.0004 error_test= 0.0566 error_train= 0.0566\n",
            "epoch=87200 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=87400 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=87600 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=87800 loss.item()= 0.0004 error_test= 0.0558 error_train= 0.0558\n",
            "epoch=88000 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=88200 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=88400 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=88600 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=88800 loss.item()= 0.0004 error_test= 0.0559 error_train= 0.0559\n",
            "epoch=89000 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=89200 loss.item()= 0.0004 error_test= 0.0570 error_train= 0.0570\n",
            "epoch=89400 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=89600 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=89800 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=90000 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=90200 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=90400 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=90600 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=90800 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=91000 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=91200 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=91400 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=91600 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=91800 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=92000 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=92200 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=92400 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=92600 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=92800 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=93000 loss.item()= 0.0004 error_test= 0.0564 error_train= 0.0564\n",
            "epoch=93200 loss.item()= 0.0004 error_test= 0.0566 error_train= 0.0566\n",
            "epoch=93400 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=93600 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=93800 loss.item()= 0.0004 error_test= 0.0570 error_train= 0.0570\n",
            "epoch=94000 loss.item()= 0.0004 error_test= 0.0563 error_train= 0.0563\n",
            "epoch=94200 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=94400 loss.item()= 0.0004 error_test= 0.0565 error_train= 0.0565\n",
            "epoch=94600 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=94800 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=95000 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=95200 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=95400 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=95600 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=95800 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=96000 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=96200 loss.item()= 0.0004 error_test= 0.0568 error_train= 0.0568\n",
            "epoch=96400 loss.item()= 0.0004 error_test= 0.0576 error_train= 0.0576\n",
            "epoch=96600 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=96800 loss.item()= 0.0004 error_test= 0.0571 error_train= 0.0571\n",
            "epoch=97000 loss.item()= 0.0004 error_test= 0.0558 error_train= 0.0558\n",
            "epoch=97200 loss.item()= 0.0004 error_test= 0.0569 error_train= 0.0569\n",
            "epoch=97400 loss.item()= 0.0004 error_test= 0.0566 error_train= 0.0566\n",
            "epoch=97600 loss.item()= 0.0004 error_test= 0.0570 error_train= 0.0570\n",
            "epoch=97800 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=98000 loss.item()= 0.0004 error_test= 0.0574 error_train= 0.0574\n",
            "epoch=98200 loss.item()= 0.0004 error_test= 0.0562 error_train= 0.0562\n",
            "epoch=98400 loss.item()= 0.0004 error_test= 0.0571 error_train= 0.0571\n",
            "epoch=98600 loss.item()= 0.0004 error_test= 0.0571 error_train= 0.0571\n",
            "epoch=98800 loss.item()= 0.0004 error_test= 0.0567 error_train= 0.0567\n",
            "epoch=99000 loss.item()= 0.0004 error_test= 0.0575 error_train= 0.0575\n",
            "epoch=99200 loss.item()= 0.0004 error_test= 0.0570 error_train= 0.0570\n",
            "epoch=99400 loss.item()= 0.0004 error_test= 0.0561 error_train= 0.0561\n",
            "epoch=99600 loss.item()= 0.0004 error_test= 0.0572 error_train= 0.0572\n",
            "epoch=99800 loss.item()= 0.0004 error_test= 0.0571 error_train= 0.0571\n"
          ]
        }
      ],
      "source": [
        "def train(model, epochs=100000):\n",
        "  model.train()\n",
        "  labels = torch.tensor(labeled['ZPPG_Performance'].values).float().view(-1, 1).to(device)\n",
        "  data = labeled.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "  data = torch.tensor(data.values).float().to(device)\n",
        "  # data = torch.tensor(train_data.values).float().to(device)\n",
        "  # labels = torch.tensor(train_labels.values).float().view(-1, 1).to(device)\n",
        "  for epoch in range(epochs):\n",
        "    predictions = model(data)\n",
        "    loss = F.mse_loss(predictions, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 200 == 0:\n",
        "      error_test = error_train = evaluate(model, labeled)\n",
        "      # error_test = evaluate(model, test_data)\n",
        "      # error_train = evaluate(model, train_data2)\n",
        "      print(f'{epoch=:5} {loss.item()=:7.4f} {error_test=:7.4f} {error_train=:7.4f}')\n",
        "  model.eval()\n",
        "\n",
        "train(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save\n",
        "# ----\n",
        "# torch.save(model.state_dict(), 'weights/mlp2.pt')\n",
        "\n",
        "# load\n",
        "# ----\n",
        "# m = MLP().to(device)\n",
        "# m.load_state_dict(torch.load('weights/mlp.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nDTgt3p0Jgm"
      },
      "source": [
        "## eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLl-ai-v1uMU",
        "outputId": "12d8182e-9fde-47b9-83b3-ebba0640113c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.5838311910629272, 9344),\n",
              " (0.5834306478500366, 96286),\n",
              " (0.5777755975723267, 905),\n",
              " (0.5765734910964966, 107278),\n",
              " (0.5731818675994873, 62718),\n",
              " (0.5727548599243164, 83512),\n",
              " (0.5722121000289917, 23565),\n",
              " (0.5717170238494873, 16423),\n",
              " (0.5715450048446655, 68204),\n",
              " (0.5703274011611938, 8415),\n",
              " (0.5677893161773682, 43792),\n",
              " (0.5653950572013855, 42742),\n",
              " (0.5627473592758179, 38055),\n",
              " (0.5623264312744141, 94304),\n",
              " (0.5618478059768677, 62298)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict solution\n",
        "topn(model, unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqh4i9be19PY",
        "outputId": "81646972-c4e3-4ce9-ab81-7afee8518e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1.8702857494354248, 3412),\n",
              " (1.8266371488571167, 2695),\n",
              " (1.8240541219711304, 7487),\n",
              " (1.8221070766448975, 2509),\n",
              " (1.821927547454834, 3773),\n",
              " (1.8169137239456177, 8721),\n",
              " (1.8135265111923218, 5386),\n",
              " (1.8075464963912964, 5751),\n",
              " (1.8061460256576538, 7243),\n",
              " (1.7997924089431763, 2004),\n",
              " (1.797755241394043, 5072),\n",
              " (1.7943958044052124, 4148),\n",
              " (1.7933684587478638, 6989),\n",
              " (1.791631817817688, 7146),\n",
              " (1.7850587368011475, 5667)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validation\n",
        "topn(model, test_data)\n",
        "topn(model, train_data2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_hf_nlp",
      "language": "python",
      "name": "venv_hf_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
