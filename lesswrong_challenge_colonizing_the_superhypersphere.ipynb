{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8n_vM3jIitW"
      },
      "source": [
        "# lesswrong challenge: Colonizing the SuperHyperSphere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3fu4tcIgHF"
      },
      "source": [
        "problem: https://www.lesswrong.com/posts/Rpjrwspx2QZuHbmPE/d-and-d-sci-fi-colonizing-the-superhypersphere-evaluation\n",
        "\n",
        "submit: https://h-b-p.github.io/d-and-d-sci-SuperHyperSphere/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aktjQ_0E0BWR"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOkR7Lp1B_6b",
        "outputId": "acc75e28-97a4-4b55-f703-703fc4e8c5bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/sfgeekgit/lesswrongDataDzppg/main/cleared_sites_formated.csv\n",
        "!wget https://raw.githubusercontent.com/sfgeekgit/lesswrongDataDzppg/main/measured_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "82HUMHLYzpwS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KQTuTq9u_WBQ"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "unlabeled = pd.read_csv('cleared_sites_formated.csv')\n",
        "labeled = pd.read_csv('measured_data.csv')\n",
        "n_features = labeled.shape[1] - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKtElfWrAiqi",
        "outputId": "d5b29791-b579-4255-ac9e-f88c555a8e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data: 9366\n",
            "test data:  1041\n"
          ]
        }
      ],
      "source": [
        "# split into training and test sets\n",
        "train_data2, test_data = train_test_split(labeled, test_size =.1, random_state = 1)\n",
        "train_labels = train_data2['ZPPG_Performance']\n",
        "train_data = train_data2.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "\n",
        "print(f'train data: {len(train_data)}')\n",
        "print(f'test data:  {len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RtIRD5cz948"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4_e6yDO-PVLk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, dataset):\n",
        "  model.eval()\n",
        "  val = dataset.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "  preds = model(torch.tensor(val.values).float().to(device))\n",
        "  labels = torch.tensor(dataset['ZPPG_Performance'].values).view(-1, 1).to(device)\n",
        "  diff = preds.detach() - labels\n",
        "  error = diff.abs().mean().item()\n",
        "  model.train()\n",
        "  return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "90VqjJY46_3T"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def topn(model, dataset, n=15):\n",
        "  model.eval()\n",
        "  to_drop = ['ZPPG_id']\n",
        "  if 'ZPPG_Performance' in dataset: to_drop.append('ZPPG_Performance')\n",
        "  preds = model(torch.tensor(dataset.drop(to_drop, axis=1).values).float().to(device))\n",
        "  ids = dataset['ZPPG_id']\n",
        "  preds_id = list(zip(\n",
        "    preds.view(-1).tolist(),\n",
        "    ids.values.tolist()))\n",
        "  return sorted(preds_id, reverse=True)[:n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PS_EWz00EXo"
      },
      "source": [
        "## model and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "eWGrZfBgAjlJ"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_inputs=n_features, hidden=64, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(n_inputs, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, 1),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6ba5xzovGe0u"
      },
      "outputs": [],
      "source": [
        "model = MLP().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAdJbaa_AuQ-",
        "outputId": "9180ac60-273b-4a86-d04b-6e0fca155b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=    0 loss.item()= 0.0006 error= 0.0740\n",
            "epoch=  200 loss.item()= 0.0006 error= 0.0702\n",
            "epoch=  400 loss.item()= 0.0006 error= 0.0684\n",
            "epoch=  600 loss.item()= 0.0006 error= 0.0685\n",
            "epoch=  800 loss.item()= 0.0006 error= 0.0688\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[95], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m=:\u001b[39;00m\u001b[38;5;124m5\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m=:\u001b[39;00m\u001b[38;5;124m7.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m=:\u001b[39;00m\u001b[38;5;124m7.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m   model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[95], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, df, epochs, log_every, lr, weight_decay)\u001b[0m\n\u001b[0;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 12\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m log_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     14\u001b[0m   error \u001b[38;5;241m=\u001b[39m evaluate(model, df)\n",
            "File \u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    158\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    161\u001b[0m         group,\n\u001b[0;32m    162\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m         state_steps,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 321\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\p\\Desktop\\_ML\\huggingface-nlp-course\\venv\\Lib\\site-packages\\torch\\optim\\adamw.py:564\u001b[0m, in \u001b[0;36m_multi_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    562\u001b[0m     denom \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_add(max_exp_avg_sq_sqrt, eps)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 564\u001b[0m     exp_avg_sq_sqrt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_sqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_exp_avg_sqs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[0;32m    566\u001b[0m     denom \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_foreach_add(exp_avg_sq_sqrt, eps)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def train(model, df, epochs=100000, log_every=200, lr=3e-4, weight_decay=0.01):\n",
        "  model.train()\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "  labels = torch.tensor(df['ZPPG_Performance'].values).float().view(-1, 1).to(device)\n",
        "  data = df.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "  data = torch.tensor(data.values).float().to(device)\n",
        "  for epoch in range(epochs):\n",
        "    predictions = model(data)\n",
        "    loss = F.mse_loss(predictions, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % log_every == 0:\n",
        "      error = evaluate(model, df)\n",
        "      print(f'{epoch=:5} {loss.item()=:7.4f} {error=:7.4f}')\n",
        "  model.eval()\n",
        "\n",
        "train(model, labeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save\n",
        "# ----\n",
        "# torch.save(model.state_dict(), 'weights/mlp2.pt')\n",
        "\n",
        "# load\n",
        "# ----\n",
        "# m = MLP().to(device)\n",
        "# m.load_state_dict(torch.load('weights/mlp.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nDTgt3p0Jgm"
      },
      "source": [
        "## eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLl-ai-v1uMU",
        "outputId": "12d8182e-9fde-47b9-83b3-ebba0640113c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.5023767948150635, 107278),\n",
              " (0.5023516416549683, 96286),\n",
              " (0.4998026490211487, 23565),\n",
              " (0.4972749352455139, 9344),\n",
              " (0.4961569905281067, 16423),\n",
              " (0.493185818195343, 905),\n",
              " (0.49086564779281616, 80395),\n",
              " (0.48947596549987793, 87620),\n",
              " (0.48929280042648315, 93762),\n",
              " (0.48920321464538574, 94408),\n",
              " (0.48849719762802124, 83512),\n",
              " (0.4879477620124817, 40297),\n",
              " (0.4876636266708374, 62718),\n",
              " (0.4860466718673706, 44719),\n",
              " (0.4857943654060364, 38055)]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict solution\n",
        "topn(model, unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqh4i9be19PY",
        "outputId": "81646972-c4e3-4ce9-ab81-7afee8518e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1.8702857494354248, 3412),\n",
              " (1.8266371488571167, 2695),\n",
              " (1.8240541219711304, 7487),\n",
              " (1.8221070766448975, 2509),\n",
              " (1.821927547454834, 3773),\n",
              " (1.8169137239456177, 8721),\n",
              " (1.8135265111923218, 5386),\n",
              " (1.8075464963912964, 5751),\n",
              " (1.8061460256576538, 7243),\n",
              " (1.7997924089431763, 2004),\n",
              " (1.797755241394043, 5072),\n",
              " (1.7943958044052124, 4148),\n",
              " (1.7933684587478638, 6989),\n",
              " (1.791631817817688, 7146),\n",
              " (1.7850587368011475, 5667)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validation\n",
        "topn(model, test_data)\n",
        "topn(model, train_data2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## experiment: balance the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bucket_histogram(df):\n",
        "    grouped = df.groupby('bucket', observed=True)\n",
        "    grouped['bucket'].count().plot(kind='bar')\n",
        "    plt.xlabel('bucket')\n",
        "    plt.ylabel('count')\n",
        "    plt.title('10% buckets of ZPPG_Performance')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHqCAYAAADlHlFZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABf/ElEQVR4nO3deXwM9/8H8NcmkfsSchISiVtQd5S4k6BU3WdQR5G0VdT9dRYtdbRuWmcpRamr6qo71H1TlLqSOHPfyfv3h99Os5I4I9nNvJ6Pxz7Ymc/Oft6Znd3XznxmViMiAiIiIiIVM8rrDhARERHlNQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiKiXDRu3DhoNBo8evQoV5932bJl0Gg0OHHiRK4+77tw7do1+Pv7w87ODhqNBps2bcrrLuVbK1euRJkyZVCgQAHY29vndXeI3ikGIsoXYmNjMXbsWAQGBsLBwQEajQbLli3Ltv3ly5cRGBgIa2trODg4oFu3bnj48KFOm8jISHTp0gUFCxZEiRIl8OOPP2ZazokTJ2BpaYmbN2/mdEl6bfLkyXkWRLp3747z589j0qRJWLlyJapVq5Zlu/r160Oj0bzwVr9+/WzbOzg4oHr16liyZAnS09OVdj169NBpZ2tri0qVKmH69OlISkrK1I9z586hZ8+e8PT0hLm5OaytrVG5cmUMHToU//zzz2vVvm/fPp3nLlCgAEqUKIGgoKDXXtbLXLlyBT169ICXlxcWL16MRYsW5ejyifSNSV53gCgnPHr0CBMmTECxYsVQqVIl7Nu3L9u2d+/ehZ+fH+zs7DB58mTExsbi22+/xfnz5/HXX3/B1NQUADBkyBDs27cP48ePx/Xr19GnTx+ULVsWtWvXBgCICD777DMMHDgQnp6euVGm3pg8eTLatm2LVq1a5erzJiQkIDQ0FKNGjUJISMgL244aNQq9e/fOct7atWuxdetW1KpVS2d60aJFMWXKFADAw4cPsWLFCvTq1Qt///03vv76a6WdmZkZfvjhBwDPgvOGDRswZMgQHD9+HGvWrFHaLV68GP3790fhwoXRpUsXlClTBqmpqbhw4QJWrFiBWbNmISEhAcbGxq/1d/jss89QvXp1pKSk4NSpU1i0aBG2bduG8+fPw83N7bWWlZ19+/YhPT0d3333Hby9vXNkmUR6TYjygcTERAkLCxMRkePHjwsAWbp0aZZt+/fvLxYWFvLvv/8q03bt2iUAZOHChco0Z2dnWb58uXK/Xr16Mnz4cOX+ypUrxc3NTWJiYl65n2PHjhUA8vDhw1d+TE5YunSpAJDjx4/nyPKsrKyke/fuObKs1/Hvv/8KAJk2bdobL+PcuXNibm4uVatWlaSkJGV6vXr1pHz58jpt4+LipGjRomJlZSXJyckiItK9e3exsrLSaZeWlibVqlUTAHLv3j0RETl8+LAYGxuLn5+fREdHZ+pHQkKCjB49WlJTU1+573/++acAkHXr1ulM//777wWATJ48+ZWXlZ3Y2FgRERk/fnyOv1bj4uJybFlEOY2HzChfMDMzg4uLyyu13bBhAz744AMUK1ZMmda4cWOUKlUKv/zyizItISEBBQsWVO47ODggPj4eABAXF4fhw4djypQpsLa2fu3+Pnr0CO3bt4etrS0KFSqEzz//HImJicr8W7duZXvYT6PRYNy4cTrT7t27h169esHNzQ1mZmbw9PRE//79kZycnG0fnj59iho1aqBo0aK4evUqACApKQljx46Ft7c3zMzM4O7ujqFDh+ocCtJoNIiLi8Py5cuVQzc9evQAAMTExGDgwIHw8PCAmZkZnJyc0KRJE5w6deqlf5PTp0+jadOmsLW1hbW1NRo1aoSjR48q88eNG4fixYsDAL788ktoNBp4eHi8dLkZxcXFoUOHDihQoADWrl2r7A3MjqWlJWrVqoW4uLhMh1QzMjIyUg6/3bp1CwAwfvx4aDQarFq1CjY2NpkeY25ujokTJ7723qGsNGzYEAB0Dt3+/vvvqFu3LqysrGBjY4PmzZvj4sWLOo/r0aMHrK2tcePGDTRr1gw2Njbo0qULPDw8MHbsWACAo6NjptfcvHnzUL58eZiZmcHNzQ3BwcGIjIzUWXb9+vVRoUIFnDx5En5+frC0tMTIkSOV1/a3336LuXPnokSJErC0tIS/vz/u3LkDEcHEiRNRtGhRWFhY4MMPP8STJ090lv3bb7+hefPmyuvdy8sLEydORFpaWpZ9uHTpEho0aABLS0sUKVIEU6dOzfQ3TExMxLhx41CqVCmYm5vD1dUVrVu3xo0bN5Q26enpmDVrFsqXLw9zc3M4Ozvjk08+wdOnT199ZZHe4iEzUpV79+7hwYMHWY47qVGjBrZv367cr169OmbMmIEyZcrgn3/+wY4dO7B48WIAzw4ZFSlSBN26dXujfrRv3x4eHh6YMmUKjh49iu+//x5Pnz7FihUrXntZ9+/fR40aNRAZGYm+ffuiTJkyuHfvHtavX4/4+PgsP/QfPXqEJk2a4MmTJ9i/fz+8vLyQnp6Oli1b4tChQ+jbty/Kli2L8+fPY+bMmfj777+VMUMrV65E7969UaNGDfTt2xcA4OXlBQDo168f1q9fj5CQEJQrVw6PHz/GoUOHcPnyZVSpUiXbGi5evIi6devC1tYWQ4cORYECBbBw4ULUr18f+/fvR82aNdG6dWvY29vjiy++QKdOndCsWbPXDqMhISG4fPkyVq1apfT5Zf755x8YGxu/dFCx9oOzUKFCiI+Px969e1G/fn0ULVr0tfr4JjI+N/BsHXXv3h0BAQH45ptvEB8fj/nz56NOnTo4ffq0TpBMTU1FQEAA6tSpg2+//RaWlpbo0aMHVqxYgY0bN2L+/PmwtrZGxYoVATwLpuPHj0fjxo3Rv39/XL16FfPnz8fx48dx+PBhFChQQFn248eP0bRpU3Ts2BFdu3aFs7OzMm/VqlVITk7Gp59+iidPnmDq1Klo3749GjZsiH379mHYsGG4fv06Zs+ejSFDhmDJkiXKY5ctWwZra2sMGjQI1tbW2Lt3L8aMGYPo6GhMmzZN52/z9OlTBAYGonXr1mjfvj3Wr1+PYcOGwcfHB02bNgUApKWl4YMPPsCePXvQsWNHfP7554iJicGuXbtw4cIF5bXyySefYNmyZejZsyc+++wz3Lx5E3PmzMHp06cz1U4GKK93URHltBcdMtPOW7FiRaZ5X375pQCQxMREEXl2aKVo0aICQABImzZtJC0tTf755x+xsLCQ0NDQ1+6b9pBZy5YtdaYPGDBAAMjZs2dFROTmzZvZ1gBAxo4dq9wPCgoSIyOjLA+Hpaeni4juIbOwsDApX768lChRQm7duqW0XblypRgZGcnBgwd1lrFgwQIBIIcPH1amZXfIzM7OToKDg1/6d3heq1atxNTUVG7cuKFMu3//vtjY2Iifn58yTft3eZNDZitXrhQA0rNnzyzn16tXT8qUKSMPHz6Uhw8fyuXLl+Wzzz4TANKiRQulnfaQmbbd9evXZfLkyaLRaKRixYoiInL27FkBIAMHDsz0PI8fP1Ye+/DhQ53Ddi+jPWS2ZMkSefjwody/f1+2bdsmHh4eotFo5Pjx4xITEyP29vbSp08fnceGh4eLnZ2dzvTu3bsLAJ1DwVpZHd598OCBmJqair+/v6SlpSnT58yZo/Qr498TgCxYsEBnudp16OjoKJGRkcr0ESNGCACpVKmSpKSkKNM7deokpqamynYpIhIfH5+pv5988olYWlrqtNP2IeP2npSUJC4uLtKmTRtl2pIlSwSAzJgxI9NytdvQwYMHBYCsWrVKZ/6OHTuynE6Gh4fMSFUSEhIAPDvE9jxzc3OdNj4+Prh27RqOHz+Oa9euYf369TAyMsLgwYPRpk0b1KpVC7/++isqVaoET09PTJgwASLySv0IDg7Wuf/pp58CgM4eqleRnp6OTZs2oUWLFlnu9dJoNDr37969i3r16iElJQUHDhxQDkEBwLp161C2bFmUKVMGjx49Um7awzF//vnnS/tjb2+PY8eO4f79+69cQ1paGnbu3IlWrVqhRIkSynRXV1d07twZhw4dQnR09CsvLyt///03+vfvjzJlymD27NnZtrty5QocHR3h6OiIsmXLYvbs2WjevLnO3gng2aE3bTtvb2+MHDkSvr6+2LhxIwAo/c1qD1aJEiWUxzo6OmLz5s2vXc/HH38MR0dHuLm5oXnz5sohzGrVqmHXrl2IjIxEp06ddNajsbExatasmeV67N+//ys97+7du5GcnIyBAwfCyOi/j48+ffrA1tYW27Zt02lvZmaGnj17Zrmsdu3awc7OTrlfs2ZNAEDXrl1hYmKiMz05ORn37t1TpllYWCj/j4mJwaNHj1C3bl3Ex8fjypUrOs9jbW2Nrl27KvdNTU1Ro0YNnbPyNmzYgMKFCyvbYUbabWjdunWws7NDkyZNdP6uVatWhbW19SttH6TfeMiMVEX7RprV6dHaMTwZ32zNzc11gsbevXuxc+dOXL16FVevXkXHjh2xcOFCeHh4oFOnTnB3d8/2AyCjkiVL6tz38vKCkZGRMv7kVT18+BDR0dGoUKHCK7Xv1q0bTExMcPny5Uxjrq5du4bLly/D0dExy8c+ePDgpcufOnUqunfvDnd3d1StWhXNmjVDUFCQTtDJqob4+HiULl0607yyZcsiPT0dd+7cQfny5V/6/FlJSkpC+/btkZqairVr18LKyirbth4eHli8eDE0Gg3Mzc1RsmRJODk5ZWpnbm6OLVu2AIAyZivjoTHtmKHY2NhMj/3tt9+QkpKCs2fPYsiQIW9U05gxY1C3bl0YGxujcOHCKFu2rBIirl27BuC/cUXPs7W11blvYmLyyof1/v33XwDItK5MTU1RokQJZb5WkSJFsh2nlXEMHwAlHLm7u2c5PeM4nYsXL2L06NHYu3dvprAcFRWlc79o0aKZvhgULFgQ586dU+7fuHEDpUuX1gliz7t27RqioqKyfD0Ar7Z9kH5jICJVcXV1BQCEhYVlmhcWFgYHB4cs9x4Bz/ZkfP755xg+fDiKFCmCiRMnonbt2koA+uSTT7Bq1apXCkTPe/4N+/n7GfvwNlq3bo0VK1bgu+++U04v10pPT4ePjw9mzJiR5WOf/6DKSvv27VG3bl1s3LgRO3fuxLRp0/DNN9/g119/VcZr5LZBgwbh7NmzmDt3rjIOJjtWVlZo3LjxS5dpbGz8wnbe3t4wMTHBhQsXMs2rV68eALzww/dlfHx8sn1+7TWTVq5cmeWJBs8/r5mZmc7enpyU8cvF87IbTJ7ddO3e18jISNSrVw+2traYMGECvLy8YG5ujlOnTmHYsGE614x6leW9qvT0dDg5OWHVqlVZzs/uiwQZDgYiUpUiRYrA0dExyys2//XXX6hcuXK2j50/fz5iYmKUb/X379/XueaLm5ubzm79F7l27ZrOtYuuX7+O9PR0ZbCr9uy258/cef4buKOjI2xtbbP84M3Kp59+Cm9vb4wZMwZ2dnYYPny4Ms/Lywtnz55Fo0aNsg1kWi+a7+rqigEDBmDAgAF48OABqlSpgkmTJmUbiBwdHWFpaamc6ZbRlStXYGRk9EphLCsbNmzAvHnz0Lp1awwYMOCNlvEmrKyslAHh9+7dQ5EiRXLtubUDgJ2cnF4p3L0O7SHWq1ev6uz1S05Oxs2bN3P8+bKyb98+PH78GL/++iv8/PyU6W9zcVQvLy8cO3YMKSkp2Q6M9vLywu7du/H++++/MOiR4eIYIlKdNm3aYOvWrbhz544ybc+ePfj777/Rrl27LB/z5MkTjB07FtOmTVPGGjk7O+uMV8jqMFR25s6dq3NfO65FGxpsbW1RuHBhHDhwQKfdvHnzdO4bGRmhVatW2LJlS5YhL6tvwf/73/8wZMgQjBgxAvPnz1emt2/fHvfu3VPOpMsoISEBcXFxyn0rK6tMYS0tLS3T4QonJye4ublleYhSy9jYGP7+/vjtt990DhlGRERg9erVqFOnTqbDPK/i1q1b6N27N4oXL65cRDE3jRkzBmlpaejatWuWh85edw/FqwoICICtrS0mT56MlJSUTPNfdPmAl2ncuDFMTU3x/fff6/T/xx9/RFRUFJo3b/7Gy35V2j0+GZ8/OTk507bxOtq0aYNHjx5hzpw5meZpn6d9+/ZIS0vDxIkTM7VJTU3NtD2Q4eEeIso35syZg8jISGVA75YtW3D37l0Az/aMaMcijBw5EuvWrUODBg3w+eefIzY2FtOmTYOPj0+2h7v+97//wcfHRycwtWnTBhMmTED//v1RvHhxLFy4MNvDTc+7efMmWrZsicDAQISGhuKnn35C586dUalSJaVN79698fXXX6N3796oVq0aDhw4gL///jvTsiZPnoydO3eiXr16yunyYWFhWLduHQ4dOpTl6eLTpk1DVFQUgoODYWNjg65du6Jbt2745Zdf0K9fP/z55594//33kZaWhitXruCXX37BH3/8oYynqlq1Knbv3o0ZM2bAzc0Nnp6eKF26NIoWLYq2bduiUqVKsLa2xu7du3H8+HFMnz79hX+Pr776Crt27UKdOnUwYMAAmJiYYOHChUhKSsrymjGvomPHjsrPrzw/2FfL2tr6nV1tu27dupgzZw4+/fRTlCxZUrlSdXJyMv7++2+sWrUKpqamrxyiX5WtrS3mz5+Pbt26oUqVKujYsSMcHR1x+/ZtbNu2De+//36WH/yvwtHRESNGjMD48eMRGBiIli1b4urVq5g3bx6qV6+uM3j5XalduzYKFiyI7t2747PPPoNGo8HKlSvfKmAGBQVhxYoVGDRoEP766y/UrVsXcXFx2L17NwYMGIAPP/wQ9erVwyeffIIpU6bgzJkz8Pf3R4ECBXDt2jWsW7cO3333Hdq2bZuDlVKuy7Pz24hyWPHixZVT5J+/3bx5U6fthQsXxN/fXywtLcXe3l66dOki4eHhWS733LlzYmpqKqdPn840b9myZeLh4SGFChWSQYMGvfSqw9pTmS9duiRt27YVGxsbKViwoISEhEhCQoJO2/j4eOnVq5fY2dmJjY2NtG/fXh48eJDptHuRZ1dwDgoKEkdHRzEzM5MSJUpIcHCwckp3VleqTktLk06dOomJiYls2rRJRESSk5Plm2++kfLly4uZmZkULFhQqlatKuPHj5eoqCjlsVeuXBE/Pz+xsLAQANK9e3dJSkqSL7/8UipVqiQ2NjZiZWUllSpVknnz5r3wb6J16tQpCQgIEGtra7G0tJQGDRrIkSNHdNq8zmn32b0WMt6KFy+utM/qStVZyepK1S9y+vRpCQoKkmLFiompqalYWVlJxYoVZfDgwXL9+vVXXo5I9leqzq5tQECA2NnZibm5uXh5eUmPHj3kxIkTr1TLi66qPmfOHClTpowUKFBAnJ2dpX///vL06VOdNtn9PbNbh9nVltVr9/Dhw1KrVi2xsLAQNzc3GTp0qPzxxx8CQP7888+X9qF79+46617k2fY2atQo8fT0lAIFCoiLi4u0bdtW51IQIiKLFi2SqlWrioWFhdjY2IiPj48MHTpU7t+/n+l5yLBoRN7RflsiIiIiA8ExRERERKR6HENERJTHEhISMg1If56Dg8NLf3uNiN4cAxERUR5bu3btS69f9eeffyo/IEtEOY9jiIiI8lhYWFimX6J/XtWqVZXrUxFRzmMgIiIiItXjoGoiIiJSPY4hegXp6em4f/8+bGxsXvqTBkRERKQfRAQxMTFwc3N76W/2MRC9gvv377/xbykRERFR3rpz5w6KFi36wjYMRK/AxsYGwLM/6Jv8phIRERHlvujoaLi7uyuf4y/CQPQKtIfJbG1tGYiIiIgMzKsMd+GgaiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj2TvO4AGS6P4dty9flufd08V5+PiIjUg3uIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1TPK6A/mdx/Btufp8t75unqvPR0RElB9wDxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqV6eBqIpU6agevXqsLGxgZOTE1q1aoWrV6/qtKlfvz40Go3OrV+/fjptbt++jebNm8PS0hJOTk748ssvkZqaqtNm3759qFKlCszMzODt7Y1ly5a96/KIiIjIQORpINq/fz+Cg4Nx9OhR7Nq1CykpKfD390dcXJxOuz59+iAsLEy5TZ06VZmXlpaG5s2bIzk5GUeOHMHy5cuxbNkyjBkzRmlz8+ZNNG/eHA0aNMCZM2cwcOBA9O7dG3/88Ueu1UpERET6K0+vQ7Rjxw6d+8uWLYOTkxNOnjwJPz8/ZbqlpSVcXFyyXMbOnTtx6dIl7N69G87OzqhcuTImTpyIYcOGYdy4cTA1NcWCBQvg6emJ6dOnAwDKli2LQ4cOYebMmQgICHh3BRIREZFB0KsxRFFRUQAABwcHnemrVq1C4cKFUaFCBYwYMQLx8fHKvNDQUPj4+MDZ2VmZFhAQgOjoaFy8eFFp07hxY51lBgQEIDQ09F2VQkRERAZEb65UnZ6ejoEDB+L9999HhQoVlOmdO3dG8eLF4ebmhnPnzmHYsGG4evUqfv31VwBAeHi4ThgCoNwPDw9/YZvo6GgkJCTAwsJCZ15SUhKSkpKU+9HR0TlXKBEREekdvQlEwcHBuHDhAg4dOqQzvW/fvsr/fXx84OrqikaNGuHGjRvw8vJ6J32ZMmUKxo8f/06WTURERPpHLw6ZhYSEYOvWrfjzzz9RtGjRF7atWbMmAOD69esAABcXF0REROi00d7XjjvKro2trW2mvUMAMGLECERFRSm3O3fuvFlhREREZBDyNBCJCEJCQrBx40bs3bsXnp6eL33MmTNnAACurq4AAF9fX5w/fx4PHjxQ2uzatQu2trYoV66c0mbPnj06y9m1axd8fX2zfA4zMzPY2trq3IiIiCj/ytNAFBwcjJ9++gmrV6+GjY0NwsPDER4ejoSEBADAjRs3MHHiRJw8eRK3bt3C5s2bERQUBD8/P1SsWBEA4O/vj3LlyqFbt244e/Ys/vjjD4wePRrBwcEwMzMDAPTr1w///PMPhg4diitXrmDevHn45Zdf8MUXX+RZ7URERKQ/8jQQzZ8/H1FRUahfvz5cXV2V29q1awEApqam2L17N/z9/VGmTBkMHjwYbdq0wZYtW5RlGBsbY+vWrTA2Noavry+6du2KoKAgTJgwQWnj6emJbdu2YdeuXahUqRKmT5+OH374gafcExEREYA8HlQtIi+c7+7ujv379790OcWLF8f27dtf2KZ+/fo4ffr0a/WPiIiI1EEvBlUTERER5SUGIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9k7zuAJE+8hi+LVef79bXzXP1+YiISBf3EBEREZHqMRARERGR6jEQERERkeoxEBEREZHqMRARERGR6jEQERERkeoxEBEREZHqMRARERGR6jEQERERkeoxEBEREZHqMRARERGR6jEQERERkerlaSCaMmUKqlevDhsbGzg5OaFVq1a4evWqTpvExEQEBwejUKFCsLa2Rps2bRAREaHT5vbt22jevDksLS3h5OSEL7/8EqmpqTpt9u3bhypVqsDMzAze3t5YtmzZuy6PiIiIDESeBqL9+/cjODgYR48exa5du5CSkgJ/f3/ExcUpbb744gts2bIF69atw/79+3H//n20bt1amZ+WlobmzZsjOTkZR44cwfLly7Fs2TKMGTNGaXPz5k00b94cDRo0wJkzZzBw4ED07t0bf/zxR67WS0RERPrJJC+ffMeOHTr3ly1bBicnJ5w8eRJ+fn6IiorCjz/+iNWrV6Nhw4YAgKVLl6Js2bI4evQoatWqhZ07d+LSpUvYvXs3nJ2dUblyZUycOBHDhg3DuHHjYGpqigULFsDT0xPTp08HAJQtWxaHDh3CzJkzERAQkOt1ExERkX7RqzFEUVFRAAAHBwcAwMmTJ5GSkoLGjRsrbcqUKYNixYohNDQUABAaGgofHx84OzsrbQICAhAdHY2LFy8qbTIuQ9tGu4znJSUlITo6WudGRERE+ZfeBKL09HQMHDgQ77//PipUqAAACA8Ph6mpKezt7XXaOjs7Izw8XGmTMQxp52vnvahNdHQ0EhISMvVlypQpsLOzU27u7u45UiMRERHpJ70JRMHBwbhw4QLWrFmT113BiBEjEBUVpdzu3LmT110iIiKidyhPxxBphYSEYOvWrThw4ACKFi2qTHdxcUFycjIiIyN19hJFRETAxcVFafPXX3/pLE97FlrGNs+fmRYREQFbW1tYWFhk6o+ZmRnMzMxypDYiIiLSf3m6h0hEEBISgo0bN2Lv3r3w9PTUmV+1alUUKFAAe/bsUaZdvXoVt2/fhq+vLwDA19cX58+fx4MHD5Q2u3btgq2tLcqVK6e0ybgMbRvtMoiIiEjd8nQPUXBwMFavXo3ffvsNNjY2ypgfOzs7WFhYwM7ODr169cKgQYPg4OAAW1tbfPrpp/D19UWtWrUAAP7+/ihXrhy6deuGqVOnIjw8HKNHj0ZwcLCyl6dfv36YM2cOhg4dio8//hh79+7FL7/8gm3btuVZ7URERKQ/8nQP0fz58xEVFYX69evD1dVVua1du1ZpM3PmTHzwwQdo06YN/Pz84OLigl9//VWZb2xsjK1bt8LY2Bi+vr7o2rUrgoKCMGHCBKWNp6cntm3bhl27dqFSpUqYPn06fvjhB55yT0RERADyeA+RiLy0jbm5OebOnYu5c+dm26Z48eLYvn37C5dTv359nD59+rX7SERERPmf3pxlRkRERJRXGIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9RiIiIiISPUYiIiIiEj1GIiIiIhI9d4oEDVs2BCRkZGZpkdHR6Nhw4Zv2yciIiKiXPVGgWjfvn1ITk7OND0xMREHDx58604RERER5SaT12l87tw55f+XLl1CeHi4cj8tLQ07duxAkSJFcq53RERERLngtfYQVa5cGe+99x40Gg0aNmyIypUrK7eqVaviq6++wpgxY155eQcOHECLFi3g5uYGjUaDTZs26czv0aMHNBqNzi0wMFCnzZMnT9ClSxfY2trC3t4evXr1QmxsrE6bc+fOoW7dujA3N4e7uzumTp36OmUTERFRPvdae4hu3rwJEUGJEiXw119/wdHRUZlnamoKJycnGBsbv/Ly4uLiUKlSJXz88cdo3bp1lm0CAwOxdOlS5b6ZmZnO/C5duiAsLAy7du1CSkoKevbsib59+2L16tUAno1r8vf3R+PGjbFgwQKcP38eH3/8Mezt7dG3b9/XKZ+IiIjyqdcKRMWLFwcApKen58iTN23aFE2bNn1hGzMzM7i4uGQ57/Lly9ixYweOHz+OatWqAQBmz56NZs2a4dtvv4WbmxtWrVqF5ORkLFmyBKampihfvjzOnDmDGTNmMBARERERgNcMRBldu3YNf/75Jx48eJApIL3OYbOX2bdvH5ycnFCwYEE0bNgQX331FQoVKgQACA0Nhb29vRKGAKBx48YwMjLCsWPH8NFHHyE0NBR+fn4wNTVV2gQEBOCbb77B06dPUbBgwRzrKxERERmmNwpEixcvRv/+/VG4cGG4uLhAo9Eo8zQaTY4FosDAQLRu3Rqenp64ceMGRo4ciaZNmyI0NBTGxsYIDw+Hk5OTzmNMTEzg4OCgDPgODw+Hp6enThtnZ2dlXlaBKCkpCUlJScr96OjoHKmHiIiI9NMbBaKvvvoKkyZNwrBhw3K6Pzo6duyo/N/HxwcVK1aEl5cX9u3bh0aNGr2z550yZQrGjx//zpZPRERE+uWNrkP09OlTtGvXLqf78lIlSpRA4cKFcf36dQCAi4sLHjx4oNMmNTUVT548UcYdubi4ICIiQqeN9n52Y5NGjBiBqKgo5Xbnzp2cLoWIiIj0yBsFonbt2mHnzp053ZeXunv3Lh4/fgxXV1cAgK+vLyIjI3Hy5Emlzd69e5Geno6aNWsqbQ4cOICUlBSlza5du1C6dOlsxw+ZmZnB1tZW50ZERET51xsdMvP29sb//vc/HD16FD4+PihQoIDO/M8+++yVlhMbG6vs7QGendZ/5swZODg4wMHBAePHj0ebNm3g4uKCGzduYOjQofD29kZAQAAAoGzZsggMDESfPn2wYMECpKSkICQkBB07doSbmxsAoHPnzhg/fjx69eqFYcOG4cKFC/juu+8wc+bMNymdiIiI8qE3CkSLFi2CtbU19u/fj/379+vM02g0rxyITpw4gQYNGij3Bw0aBADo3r075s+fj3PnzmH58uWIjIyEm5sb/P39MXHiRJ1rEa1atQohISFo1KgRjIyM0KZNG3z//ffKfDs7O+zcuRPBwcGoWrUqChcujDFjxvCUeyIiIlK8USC6efNmjjx5/fr1ISLZzv/jjz9eugwHBwflIozZqVixIn9jjYiIiLL1RmOIiIiIiPKTN9pD9PHHH79w/pIlS96oM0RERER54Y0C0dOnT3Xup6Sk4MKFC4iMjETDhg1zpGNEREREueWNAtHGjRszTUtPT0f//v3h5eX11p0iIiIiyk05NobIyMgIgwYN4unsREREZHBydFD1jRs3kJqampOLJCIiInrn3uiQmfZ6QVoigrCwMGzbtg3du3fPkY4RERER5ZY3CkSnT5/WuW9kZARHR0dMnz79pWegEREREembNwpEf/75Z073g4iIiCjPvFEg0nr48CGuXr0KAChdujQcHR1zpFNEREREuemNBlXHxcXh448/hqurK/z8/ODn5wc3Nzf06tUL8fHxOd1HIiIionfqjQLRoEGDsH//fmzZsgWRkZGIjIzEb7/9hv3792Pw4ME53UciIiKid+qNDplt2LAB69evR/369ZVpzZo1g4WFBdq3b4/58+fnVP+IiIiI3rk3CkTx8fFwdnbONN3JyYmHzIgMgMfwbbn2XLe+bp5rz0VE9Kbe6JCZr68vxo4di8TERGVaQkICxo8fD19f3xzrHBEREVFueKM9RLNmzUJgYCCKFi2KSpUqAQDOnj0LMzMz7Ny5M0c7SERERPSuvVEg8vHxwbVr17Bq1SpcuXIFANCpUyd06dIFFhYWOdpBIiIionftjQLRlClT4OzsjD59+uhMX7JkCR4+fIhhw4blSOeIiIiIcsMbjSFauHAhypQpk2l6+fLlsWDBgrfuFBEREVFueqNAFB4eDldX10zTHR0dERYW9tadIiIiIspNbxSI3N3dcfjw4UzTDx8+DDc3t7fuFBEREVFueqMxRH369MHAgQORkpKChg0bAgD27NmDoUOH8krVREREZHDeKBB9+eWXePz4MQYMGIDk5GQAgLm5OYYNG4YRI0bkaAeJiIiI3rU3CkQajQbffPMN/ve//+Hy5cuwsLBAyZIlYWZmltP9IyIiInrn3igQaVlbW6N69eo51RciIiKiPPFGg6qJiIiI8hMGIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlK9PA1EBw4cQIsWLeDm5gaNRoNNmzbpzBcRjBkzBq6urrCwsEDjxo1x7do1nTZPnjxBly5dYGtrC3t7e/Tq1QuxsbE6bc6dO4e6devC3Nwc7u7umDp16rsujYiIiAxIngaiuLg4VKpUCXPnzs1y/tSpU/H9999jwYIFOHbsGKysrBAQEIDExESlTZcuXXDx4kXs2rULW7duxYEDB9C3b19lfnR0NPz9/VG8eHGcPHkS06ZNw7hx47Bo0aJ3Xh8REREZBpO8fPKmTZuiadOmWc4TEcyaNQujR4/Ghx9+CABYsWIFnJ2dsWnTJnTs2BGXL1/Gjh07cPz4cVSrVg0AMHv2bDRr1gzffvst3NzcsGrVKiQnJ2PJkiUwNTVF+fLlcebMGcyYMUMnOBEREZF66e0Yops3byI8PByNGzdWptnZ2aFmzZoIDQ0FAISGhsLe3l4JQwDQuHFjGBkZ4dixY0obPz8/mJqaKm0CAgJw9epVPH36NJeqISIiIn2Wp3uIXiQ8PBwA4OzsrDPd2dlZmRceHg4nJyed+SYmJnBwcNBp4+npmWkZ2nkFCxbM9NxJSUlISkpS7kdHR79lNURERKTP9HYPUV6aMmUK7OzslJu7u3ted4mIiIjeIb0NRC4uLgCAiIgInekRERHKPBcXFzx48EBnfmpqKp48eaLTJqtlZHyO540YMQJRUVHK7c6dO29fEBEREektvQ1Enp6ecHFxwZ49e5Rp0dHROHbsGHx9fQEAvr6+iIyMxMmTJ5U2e/fuRXp6OmrWrKm0OXDgAFJSUpQ2u3btQunSpbM8XAYAZmZmsLW11bkRERFR/pWngSg2NhZnzpzBmTNnADwbSH3mzBncvn0bGo0GAwcOxFdffYXNmzfj/PnzCAoKgpubG1q1agUAKFu2LAIDA9GnTx/89ddfOHz4MEJCQtCxY0e4ubkBADp37gxTU1P06tULFy9exNq1a/Hdd99h0KBBeVQ1ERER6Zs8HVR94sQJNGjQQLmvDSndu3fHsmXLMHToUMTFxaFv376IjIxEnTp1sGPHDpibmyuPWbVqFUJCQtCoUSMYGRmhTZs2+P7775X5dnZ22LlzJ4KDg1G1alUULlwYY8aM4Sn3REREpMjTQFS/fn2ISLbzNRoNJkyYgAkTJmTbxsHBAatXr37h81SsWBEHDx58434SERFR/qa3Y4iIiIiIcgsDEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREameSV53gIgoJ3kM35Zrz3Xr6+a59lxE9G5xDxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREakeAxERERGpHgMRERERqR4DEREREameXgeicePGQaPR6NzKlCmjzE9MTERwcDAKFSoEa2trtGnTBhERETrLuH37Npo3bw5LS0s4OTnhyy+/RGpqam6XQkRERHrMJK878DLly5fH7t27lfsmJv91+YsvvsC2bduwbt062NnZISQkBK1bt8bhw4cBAGlpaWjevDlcXFxw5MgRhIWFISgoCAUKFMDkyZNzvRYiIiLST3ofiExMTODi4pJpelRUFH788UesXr0aDRs2BAAsXboUZcuWxdGjR1GrVi3s3LkTly5dwu7du+Hs7IzKlStj4sSJGDZsGMaNGwdTU9PcLoeIiIj0kF4fMgOAa9euwc3NDSVKlECXLl1w+/ZtAMDJkyeRkpKCxo0bK23LlCmDYsWKITQ0FAAQGhoKHx8fODs7K20CAgIQHR2NixcvZvucSUlJiI6O1rkRERFR/qXXgahmzZpYtmwZduzYgfnz5+PmzZuoW7cuYmJiEB4eDlNTU9jb2+s8xtnZGeHh4QCA8PBwnTCkna+dl50pU6bAzs5Oubm7u+dsYURERKRX9PqQWdOmTZX/V6xYETVr1kTx4sXxyy+/wMLC4p0974gRIzBo0CDlfnR0NEMRERFRPqbXe4ieZ29vj1KlSuH69etwcXFBcnIyIiMjddpEREQoY45cXFwynXWmvZ/VuCQtMzMz2Nra6tyIiIgo/zKoQBQbG4sbN27A1dUVVatWRYECBbBnzx5l/tWrV3H79m34+voCAHx9fXH+/Hk8ePBAabNr1y7Y2tqiXLlyud5/IiIi0k96fchsyJAhaNGiBYoXL4779+9j7NixMDY2RqdOnWBnZ4devXph0KBBcHBwgK2tLT799FP4+vqiVq1aAAB/f3+UK1cO3bp1w9SpUxEeHo7Ro0cjODgYZmZmeVwdERER6Qu9DkR3795Fp06d8PjxYzg6OqJOnTo4evQoHB0dAQAzZ86EkZER2rRpg6SkJAQEBGDevHnK442NjbF161b0798fvr6+sLKyQvfu3TFhwoS8KomIiIj0kF4HojVr1rxwvrm5OebOnYu5c+dm26Z48eLYvn17TneNiIiI8hGDGkNERERE9C7o9R4iIiL6j8fwbbn2XLe+bp5rz0WkD7iHiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUzySvO0BEROQxfFuuPdetr5vn2nOR4eAeIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPQYiIiIiUj0GIiIiIlI9BiIiIiJSPZO87gAREVF+5jF8W64+362vm+fq8+UX3ENEREREqsdARERERKrHQERERESqx0BEREREqsdARERERKrHQERERESqp6rT7ufOnYtp06YhPDwclSpVwuzZs1GjRo287hYREZFByk+XFFDNHqK1a9di0KBBGDt2LE6dOoVKlSohICAADx48yOuuERERUR5TTSCaMWMG+vTpg549e6JcuXJYsGABLC0tsWTJkrzuGhEREeUxVQSi5ORknDx5Eo0bN1amGRkZoXHjxggNDc3DnhEREZE+UMUYokePHiEtLQ3Ozs46052dnXHlypVM7ZOSkpCUlKTcj4qKAgBER0e/9nOnJ8W/9mPexpv08U2xtpyTm7UBuVsfa8s5rC1n5OfaAL5XZtVeRF7eWFTg3r17AkCOHDmiM/3LL7+UGjVqZGo/duxYAcAbb7zxxhtvvOWD2507d16aFVSxh6hw4cIwNjZGRESEzvSIiAi4uLhkaj9ixAgMGjRIuZ+eno4nT56gUKFC0Gg077y/0dHRcHd3x507d2Bra/vOny83sTbDxNoMV36uj7UZptysTUQQExMDNze3l7ZVRSAyNTVF1apVsWfPHrRq1QrAs5CzZ88ehISEZGpvZmYGMzMznWn29va50FNdtra2+W5D0GJthom1Ga78XB9rM0y5VZudnd0rtVNFIAKAQYMGoXv37qhWrRpq1KiBWbNmIS4uDj179szrrhEREVEeU00g6tChAx4+fIgxY8YgPDwclStXxo4dOzINtCYiIiL1UU0gAoCQkJAsD5HpGzMzM4wdOzbTYbv8gLUZJtZmuPJzfazNMOlrbRqRVzkXjYiIiCj/UsWFGYmIiIhehIGIiIiIVI+BiIiIiFSPgYiIiIj03rse8sxAZMC2bNmCU6dO5XU33rktW7Zg+PDhSElJyeuu5Lhdu3Zh3rx5SEtLy+uu5DjWZpjy8/YG5O/68nNt69atQ9euXZGcnPzuniRHfiyMct3cuXNFo9GItbW1HDt2LK+7887MmTNHNBqNlCxZUkaMGCHJycl53aUco12HFStWlIULF0pqampedynHsDbDlJ+3N5H8XZ8aanN3d5dOnTpJUlLSO3keVV2HKD8QETx9+hSjRo3C1KlTcfHiRXzwwQfYsmULatasmdfdy1Hx8fG4fv06li9fjjt37mDz5s1IT0/HV199BRMTw37pPnz4EEeOHMGSJUtw6NAhLF++HOnp6ejTpw+MjY3zuntvhbUZpvy8vQH5u778XBvw7LfPVq5cCRMTE3z77bcICgrCihUrYGpqmrNP9E5iFr1zsbGxIiJy4cIF6dChgzg6OsrRo0fzuFc5Ly4uTkREoqKiZOTIkVKzZk0ZNmxYvvj28+jRIxERefz4sXTq1Elq164t8+fPzxd7HFibYcrP25tI/q4vP9eWnp4uIiLx8fGyePFiqVatmnTo0CHH9xQxEBmg9PR0nRf5xYsX800o0r7wM/4/JSVFRERiYmJk1KhRyoaunW4oMtampV2PT548MegPV9Zm+LXlt+1NJH/Xp5ba0tLSRESUbSshIUF++OGHdxKKGIgMwKu8yeaHUKStMzU1VZKTk+Xp06fKPO0GYqgburY27cadkJCQad6TJ0+kc+fOBvfhytoMu7b8uL2J5O/61FBbcnKyREdHy7179zK1SUxMfCehiIFIz2nfiKOjo+WTTz6RTp06SadOneTgwYMSHR2t09aQQ5G2zqioKGnZsqXUrFlTKleuLOPHj5fHjx/rtDW0DT3jOuzatavUr19fPvjgA1mwYEGmtob24cranjHU2vLj9iaSv+tTS22NGjWSypUri7Ozs/Tr109Onz6t0/ZdhCKedq/njIyMEBcXh8qVK+Pvv/+Gs7Mzrl69ij59+mDChAkIDw9X2pYrVw5jxoxBw4YN0aJFCxw7diwPe/56jIyMkJCQAF9fX5iYmKBLly5o27YtpkyZgi5duuDIkSNKW2trawwfPhyNGzfGvn37MHr0aKSmpuZh71/MyMgI8fHxqFatGmJiYlC7dm24u7vj008/RVBQEO7cuQPg2YD5ggULYs6cOfDw8MDKlSuxePFivT61m7UZbm35dXsD8nd9+b22xMRE+Pn5oWDBghg5ciSmT5+O7du3Y9CgQfj555+VtmZmZujatSv69euH69evIygo6O1PyX/rSEXvjHbX56xZs6Ru3bo6x1XHjh0rNWvWlN69e0tERITO486fPy8dOnQQV1dXCQ0NzdU+v41t27ZJmTJl5OHDh8q0a9euSalSpaRJkyZy/PhxEfnvW0RkZKSMHDlS6tatKwMHDtTrbz+rV6+W8uXLS1RUlDLtwIEDYmtrKx999JGEh4eLyH9jUx49eiSdOnUSPz8/mTVrllKzPmJthllbft7eRPJ3ffm5toMHD0rJkiXl9u3byrR///1XAgICxM/PT9avX6/TPi4uThYvXix16tSRDz/88K0GkTMQGYBJkyZJuXLllDPLtL799lupWbOmTJo0SRITE3UCU1RUlJQqVUpKlSqV6dCavvr111+lWLFi8uDBAxF5tktUROT69etSvHhx+eijj5S2GTfoOnXqSLly5eTvv//O3Q6/hgULFkjp0qWV+9r+nzlzRmxsbGTAgAGZ5omIlCxZUurWravz5qBvWJvuPBHDqC2/bW/PD37Pb/VllJ9rO3LkiLi5ucmZM2dERJRDYXfu3JH69etLkyZNJCwsTER0x9e2bt1anJ2d5ezZs2/83AxEBuCHH36Q0qVLKy/ijC/wzz//XLy8vJQNQ/umsHTpUtFoNLJp06bc7/AbunTpkpiZmcmiRYuUadq0f/bsWTE2NpYVK1boPObUqVNibGwsGzZsyNW+vq7Q0FAxMjLSWR/a9bh582YxMzOT33//PdNjTExM5Ndff83Vvr5IVmdc5Zfastqbk59ry0/bW8aBuNrTz/NLfVltcxcvXswXtWXl33//FQcHBxk/frwyTVvbjRs3xMbGRqZOnarMS09PlwsXLohGo3nr2hiI9MjzL3zt/dTUVCldurQEBgZmOr1SRMTOzk7mzZun89jz58/rbRh60WGEcePGiZOTk/z2228i8uxvoK21UaNGMmjQIGW6iMj9+/eVbxL6ILva4uLipG/fvlKjRg05cOCAiPxXQ2RkpFSqVEmmT5+uM/3kyZN6dRVybW1JSUnKoSKR/FGb9gM1NjZWtm/fLiLP+hofH5+valu8eLHOPEPf3kT+qy8mJkbatGmjrD8Rw68v49lkT548kcTERGU7HDt2bL6oLSuLFi0SIyMjWb58uYjo1ta1a1dp166dMl3rypUrb90nw7+EZT6RlpYGY2NjpKamIiYmBgULFoRGo0FKSgoKFCiAn3/+GQEBAWjbti1Wr14NMzMzAEBsbCxKlSoFR0dHnWVVqFABFSpUyKtysqWtMy4uDtOnT0dYWBjMzMwwadIkWFlZoV27drh58yaGDBmC9PR0tGrVSrnSqpWVVaYrk7q6usLV1TUvSslEW1tsbCzGjBmDsLAwmJiYYPbs2bC3t0fHjh1x9+5djBs3DqNHj0aDBg0AAHZ2dihUqFCmwY5VqlTJizKypR1k/P7776NmzZoYPXo0ihYtCktLS3Tu3Nlga9Out+joaJQvXx7du3dH06ZNodFoYGFhYdC1iYhSm6+vL9zc3FCrVi3lvaFDhw4Gu70Buuvuvffew82bNyEiaNq0KQDDri89PR3GxsaIiYlBjx49cP/+fSQmJmLMmDH46KOP0LFjR9y6dcvgaxs2bBiioqKQkpKCnj17onbt2ujduzcuX76M3r17IzU1FR9//LFSm4jAwcEh0zJLly799h1760hFby3jdSN8fX1l1KhR8uTJk0zt9uzZIy4uLuLn5yd//PGHnD9/XpYuXSq2trZ69Y00O9o6o6OjpWzZstK4cWP56KOPxN3dXWrXrq20O3nypPTq1UssLS1l3LhxsmbNGvnuu+/EzMxM9uzZk1fdf6GMp2iXLl1a/P39JSQkRDw9PaVJkyZKuy1btkjLli3F29tbFi9eLIcPH5Z58+aJlZWVHDp0KK+6/8r++OMP0Wg0UqBAAenbt6/ONUI2b94sLVq0MKjatN9So6KipHjx4tKiRYss223dutVg11tiYqLUqFFDWrVqle2hs549exrU9iaiu+7c3d2lXbt2sm7dOilVqpTs3btXaXfq1CmDez/RiomJkVKlSknLli1lzZo1EhgYKKVKlVJqP3HihHz88ccGW5u3t7cEBgbKlClTpHHjxuLq6ir9+/eXR48eSUJCggwbNkw0Go307dtXpk2bJlOnThVTU1PZsWPHO+kTA5GeSExMlICAAHF2dpYCBQrIuHHjdC62pXXjxg2pXbu2eHl5iaurq3h4eMjPP/+c+x1+Q4mJidKoUSNp06aNpKamSnp6uvz777/i4uKic8z73r17snDhQvH09JRy5cpJ5cqVZd26dSKS9TF1fRAfHy+1a9eWdu3aKR88GzZskObNm+sc4rxw4YKMGDFCrK2tpWTJkuLt7S2//PJLXnX7tYSFhcmAAQNk27ZtYmxsLL1799YJRTdv3pSRI0caVG2xsbFSsmRJadasmTJt+/btsmLFClmwYIHy4XP27FmDq03k2XiT+vXrK+MMv/rqK+nZs6cEBATI6tWrJTo6WuLi4mT+/PkGtb2JiDx9+lQ8PDyUQyj//vuvFClSREaOHKnTzhDfT9LT0+WLL77QeV1GRERI3bp15d69e8pFQmNjY2XevHni4eFhMLWJiAwePDjTFxB/f3/RaDTSvn175fW6ZcsWqV27trz33nvi5+enjM17F7UxEOmJP/74QwICAuT8+fOycOFC0Wg0mUJRxm93Z8+elRMnTsi1a9dE5NmLQ59f/Fq///67VKlSRS5cuCAiz/qdkJAg1apVkzlz5mRq//jxY4mKitIZNK6vdf7000/SsmVLuXv3rjJt5syZUrJkSfH39xd/f3/ZsmWL8gEbFhYm9+7dU9rrc21aT548EQ8PD7l37578/vvvYmxsLF988YUMHz5cOnTooLxGDam2GTNmiLm5uXz//fciItKnTx957733pHjx4lKoUCEpX768nDx5UmlvSLWJPPtAcXZ2VsZDVahQQYYNG6Zc+C44OFjZI21I25uIyEcffSSNGjXSmTZz5kxxcHBQ3mMyevLkiUHV16NHD+nZs6cyqHjp0qViY2MjlSpVkvLly8vAgQOVWgxt3XXr1k1CQkJERJTLWkydOlX8/PzE19dXJk2apNQdExMjKSkpyufhu6qNgUhP3Lx5UzZu3Kik/oyhKOPhM32+fsSriIqKkhEjRihngmjDQYsWLWTs2LEi8l/wyxgA9XnD1kpLS5N9+/Yp6+i3334TjUYjAwYMkB9//FECAgLE3d1drl69msc9fTPa9dGqVSvlzKqTJ0+KkZGRGBkZybJly/Kye28sNTVVPv30U6lVq5ZUrFhRKleuLCdPnpS7d+/KkydPpHr16vLee+/p9TWFXuTChQtSo0YN2bJlizRu3FjOnTunzJs2bZr4+PjIwYMHdR5jCNubSNbvESdOnJBSpUrJwoULReS/98ysfvtL3/Xo0UPKly8vs2fPllmzZomxsbFMmDBBQkNDZdKkSVKtWjVZsmSJTkAwlNpat24tfn5+OtMqVaok33//vQQHB4u3t7fyOZFbtTEQ6RHtytZu5IsWLcq0p2jLli1y6tSpvOriW3n+xZzxzeyjjz6SwYMHK/d3796d6VLt+uz5D8uYmBgZO3asLFmyRGe6nZ2dTJ48OTe7luM+/fRTGT16tIg8u2ioubm5GBkZSXBwcJa/O6TPMp7F079/f6levXqmMUHXr18XCwsL5WweQ5OWlibvvfeeFClSREqVKpXp2kglS5ZUzkgyJC8KqN26dZOSJUsa7C+9ZzybODAwUNq2bStVq1aVzz//XKddzZo1lcOFhkJb25UrV8TR0VGqVq0qwcHBUrx4cSUgJSYmSqFChWT//v252jeeZaZHNBqNzr99+vQBAHzyyScwMjKCiOCbb77Bzp0786yPb0Nbl5aRkRFSU1NhYmICEYGlpSUA4KeffkJQUBB2796dF918I0ZGur+CY21tjcGDB8PGxgYAkJqaikePHqFcuXIoV65cXnTxraWnp8PIyAjFihXDgwcPMG/ePIwYMQJ79+5FUlISGjZsiMTERMydO1c5C1LfGRsbK2cqzZkzB1u3bs10duaTJ0/g4uICd3f3POrlm9PWtmbNGrRt2xZXr17FhQsXUKRIEeU1W7VqVXh5eeVxT1/f89sc8N9r9IsvvkC7du2wdOlS9O3bFyKS6f1Hn2k0GuW9cfv27dBoNAgKCkLRokUBQJlXoUIFFCpUyKDq0/azdOnSOHjwIEaOHIno6Gh06tQJU6ZMAQCcPXsWlpaWcHZ2ztW+MRDpIY1Go2zYffr0gbGxMXr37g0AWLVqFd5///087mHOExHY2dlh8+bN6NGjB1atWoWGDRvmdbfeirW1tfJ/ExMT7NixA48fP0aJEiXysFdvTvsB5OfnhwYNGkBEsHr1avj6+gIAduzYgdTUVIMJQ1rGxsbK9tayZctM80+dOoWCBQuiYMGCedC7t2NsbAwAKFmyJL777jv06tULQ4YMQVRUFEqXLo0zZ87g999/x4ABA/K4pzlD+xotWbIkPDw88Ntvv6Fv374GExYy0n5R1PY9OTkZe/fuxeDBgxETE4MdO3Zg3bp12Lhxo0HWBzwLRRs2bMg0/dSpU3BwcFC+JOeaXN0fRa9Fu2tx8eLFYmxsLNu2bVOmG8px4lfVo0cPKVq0qBgbG8vKlStFJP/UeeXKFVm4cKGYmZkpZ38YsrCwMPnyyy91Tus1tPFer+Ly5cuyYMECMTc31/ur+76qmzdvSt26dcXLy0vc3NykZMmSsnbt2rzuVo7Svv62bt0qxsbGcuvWLYMd/yXyXz3nzp0TJycncXV1lRo1aoibm5uy7gx1m3u+31euXJFvv/1WTE1N8+S9UiMikrsRjF7HqVOn4Ovri8WLFyMoKAja1WWo3wieJ///Dahdu3bYsGEDNm/ejA8++CDf1Pn48WNMnz4d69evxzfffIOPPvrIoHZvZychIQEWFhZ53Y135tGjR/j666+xZs0afPfdd2jTpk2+WG9aV65cQUpKCmxsbODh4ZFvtreMwsLC8PjxY728QO2bunfvHhYtWoTixYvDx8cH1atXz1frbvPmzfjpp5/QuXNntGrVKte3OQYiPRcdHY2IiAiULFkyX73wn3f9+nXcu3cP9erVy1d1igju3r2LmJgYlCtXLl/Vlp+JCP7991/ExMTAx8cn36w37aFBtckPYTY/1PAqHj16hMKFC+fJNsdA9A5l9QJ+mzckfd0gsqvpTWvVpzqz60t++GBhbYYpP9cG5Pz7iT7Jz+vubdebPrzvMxC9I9qzO5KTk3Hv3j0YGxvDzc1N+T2W/EJbZ0JCAnbu3Im0tDS4uroqA20Nmba2xMREnDhxAikpKfD09ISHh4fOfEPE2libPuL7iWGuu/yy3hiI3gFt0o2OjsYHH3yAiIgIpKSkwNXVFYsWLUL58uXzuos5QltnTEwMqlevDmtra9y4cQMODg6oVasWli9fbrABMGNtvr6+KFCgAC5cuID33nsPdevWxfTp0wFk/vajva8P33ayw9pYmz7i+4lhrrv8tN4Mex+dntJoNEhKSkKjRo3g4uKCH374AVOmTIG1tTXq1q2LdevWITk5WWmfnp4O4NlAVUOivTxAt27d4O3tjf379+P48eOYOnUq/vzzTzRp0gQPHjwA8F+NwLOBgfpOex2Q1q1bo0SJEvj9999x7NgxtGvXDitWrEC7du0APDvNNy0tTTne/eTJk7zs9ithbaxNH/H9xDDXXb5abzl4xhpl8Pfff0vp0qV1fgNJRKRXr15iZWWlXPVWezroyZMnpWHDhspPdxiKlJQUqV+/vnKZfK2LFy9KiRIlpHHjxsq09PR0uXfvnpiamsqCBQtyu6uvLTIyUmrWrCmbNm1SpsXFxcm2bdukUKFC0rFjR532//zzj5iYmCg/PqjPWNt/WJv+4PvJfwxp3eWX9cY9RO+AiCAqKgp3795VrlSs3SP0ww8/oG3btujduzciIiKU3aMWFhY4dOgQ5s+fn2f9fhNGRkaIiIjA6dOnlWkignLlymHDhg04e/YsvvjiCwDPvkkULFgQn3/+OXbv3o3Y2Ni86vYrMTExwd27d3Vqs7S0REBAAH744Qfs27cP06ZN02nfoUMHHDlyJC+6+1pYG2vTB5JhxIb28FB+eT/JuDcEyH/rLqP8st4YiHLIhg0bsHr1agDPVni1atVQtmxZDBkyBCICU1NTJRTNmzcPnp6eGDduHOTZ78mhbNmymDJlCuLi4pCampqXpbwy7RtYSEgI9u/fj19//RXAf7tQK1WqhC+//BLHjh3Do0ePADwLfk2aNIGFhYVeDSCULIbSWVlZoWvXrti3bx8OHz6sTDc2NkajRo3w0Ucf4ejRo0hJSQEAuLu7o0mTJrhy5YpercOsarO0tMwXtaWlpencT01NzTfrTVtbxg/W/FIb8Kw+jUaDlJQUpKWlwcjIKN+8n2jriY+PVw4N5Zdt7vmgByDfrDceMsshc+fOlYCAAImPj1cOg/38889SpUoVGTp0qHJFTu2PSXbv3l1atmyps4wLFy7I/fv3c7fjr0jb76zuX7lyRVq0aCHNmjVTfgVda926deLq6pqprsePH7+7zr4mbS0pKSny8OFDefTokTLt0KFDUqlSJQkKCpIzZ87oPG7evHlStGjRTLVERETkTsdfgbaOpKQkuXDhghw/flwSExNFxPBr025T0dHRmXa9Hz161KBr0663yMhI6d27t1y7dk2ZZ+i1ifw3VCA6Olpat24tc+fOVabll/eTmJgYcXNzEx8fH0lJSRERkdDQUINed9ra4uPjZfPmzbJw4UKlfxcvXjTo9SbCQ2Y5pnLlyspFFLWHwZo3b47AwEDs3bsXgwYNAvDfbwsVLlwYFhYWSE5OVr4Jli9fHq6urnlTwAukp6fD2NgYsbGx6N+/P27duqX8KCbw7Pdohg4ditjYWHz33XdYsWKF8tiHDx/C1dVV+ZvI/++tcHBwyP1CsqCtLSYmBh06dIC/vz8aNmyIzz77DAkJCXj//fcxceJEHDhwAN9++y127dqlPDY2NhZeXl7KOtV+c3JycsqTWp6nrS06OhqBgYHo2LEjWrdujcDAQKW2SZMmGWRtWunp6WjUqBH69++PYcOGKdNr1qyJr776CgcOHMC0adMMqjbtKczR0dEoV64c7t+/D29vb2V+zZo1MWHCBINeb0ZGRoiNjUWVKlUgIqhXr57S19KlS2Pw4MGIjY3FrFmzDOr9JOO6K1++PExNTSEiOHjwIACgVq1aBrvNiYhS2/vvv4///e9/GDVqFHx8fPDvv/+iXLlyyueAoa03RV6msfymYcOG0qxZM51pT58+lQkTJkjFihWlevXqMmPGDBk6dKgUKFBAtm7dmkc9fX1xcXFSo0YN0Wg00rBhQ7l165aIiPLNR+TZt5+uXbuKk5OTVKlSRVq0aCEWFhbyyy+/5FW3X0i7hyEmJkZKly4trVu3lg0bNsiYMWPE19dXZs+erbT9/fffpW7dulK2bFlp1KiRdO/eXczMzGT9+vV51f0Xer629u3by19//SXr168Xb29v5XfxRJ795lPdunWlTJkyBlHb8/r37y9du3YVe3t7GTBggM683bt3S506dQymtox7vTw9PaVt27bKvMTERImPj1e+pW/evNmgXpMZpaenS0hIiLRo0UKZdu3aNQkNDZWnT5+KyLMTTbp06SKOjo4G8X6i3cMVFRUlxYsXl86dO0tsbKyUKlVKevbsqdPW0N5PtBISEqR69eoSFBQk9+/fl4cPH0rlypVlxowZSpvQ0FCDWm8Z8TpEOUA7lubgwYMYOHAgOnXqhCFDhijz4+PjcerUKcycORP379+Hvb09+vfvj5YtW+r19SW00tLSMGLECJw+fRoffPABtm7diuTkZCxfvhweHh5ITU1VrjMRFhaG69ev4+eff4aHhweqV6+u/DK6PtaZmpqKTz75BI8fP8a6detQoEABAEC7du2QnJyM3377TWl7+fJlnDt3DuvWrYO3tzcaNGiAgIAAva0tJSUFbdu2hampKVatWgVTU1MAgL+/PwYMGABbW1tUqlQJhQoVwqVLl3D+/HmsX78eXl5eel8b8N/1T/r37w8LCws0atQIbdq0Qd++ffH9999jz549qFWrFu7du4fTp08bzHpLTk6Gp6cnHB0dcebMGQDAxIkTcfr0aYSHh8PLywuzZ8+Gvb09zp07h8uXLxtMbVoigmbNmuHDDz9Ev3790Lt3bxw7dgxhYWEAgK+++gp9+/bFkydPcPnyZYN5P4mLi0PRokXRpEkT/PLLLwCAZcuWYeTIkVi/fj1q166ttDW09xMAOHr0KPr376+8TwBAly5dULlyZaSnp6NBgwaoUaMGnjx5ggsXLmDNmjUGsd4UeRLD8qnIyEj57LPPxM/PT5YtW5Zlm5SUFGUMhyH9mvuiRYvkm2++kdTUVNmyZYs0bNhQ/Pz85ObNmyKiu6foefpcZ0REhHzyySeyePFiEfmvjg0bNkidOnUkOTnZYGtLTk6WmTNn6hzPX79+vZiYmEjZsmWldOnSUqhQoUxjGbT0uTaR/76Rr127VgYOHCgiImvWrBELCwupVq2auLq6yqVLl7J8rL7X1q5dO3FycpKdO3dKp06dpHz58jJq1Cj5/PPP5b333hMPDw+Jjo7O8rH6Xlt6erokJCRIYGCgbNiwQZYsWSI+Pj5y4MABuXHjhgwdOlQcHR3lp59+yvbx+lrf7t27ZdSoUTrTzp07J8WLF5fp06eLiOG+V4o82ytpYmIiN27cEBGR7du3i7GxsdSvX1+qVKki1tbWOnvWM9L32kSeneFEOej27dvSunVrqV+/vnz77bfKdO1ubkN4UYg8++BctWqVzrSM10jatGmTNGrUSPz8/JTDZ6mpqXo3SC4rGWtLSEiQ7du3S3x8vE6btWvXSoUKFXQGj2s/gPXZ8+stKSlJqeHo0aPi4uIiM2bMkJs3b0pkZKQEBgZKrVq1DPY1KSKyf/9+qVChgrIOO3ToICYmJhIYGKi00fd1l1VtnTt3Fo1GIzVr1pS///5bmX7hwgUpW7asfPbZZwb9ftKjRw8pVaqUDBw4UObMmaMzb8CAAeLl5ZXpZA59lLG25ORkZXrG9TJ8+HBxdnbW25NmsvP8ektPT5fatWuLtbW1dOjQQYyMjGT+/PkSFxcnIiKjRo0SR0dHefjwYV51+a1wUHUOc3d3x8yZM1GhQgWsWbMGzZs3R0REhHIVao1Go9+7DP9fREQEVqxYgfj4eGUAnLm5uTKQ+sMPP8Snn36KAgUKoHv37vj3338xb948+Pn5ISYmJi+7/lLa2uLi4mBubo6mTZvCwsJC5/R07RVjtVauXInWrVtnecqpPsm43gDA1NRUGaRZqFAhrFy5El988QU8PDxgZ2cHX19fJCcn69Vpvdl5vjbg2eFcNzc3mJmZwcLCAjNnzsTmzZsxcOBAHDlyBH379gUAvf/hzIy1adfFqlWrMHz4cLRu3Rre3t7K67N8+fIoVqwYwsLCDPL9RLsNjR49GlZWVvjuu++Udao95bxp06awtLTUWdf6KuP7ifaQO/DsvV67ztq1awcHBwflELy+v49oPf85oNFosGvXLsyaNQsffvgh3n//fXTs2FF5DWrXW2RkZN52/A3p97uEgSpWrBgmTpyIGTNmICYmBq1atULLli1x4MABZYPXd9qz5h48eACNRqOEA2NjY2Uj14YiMzMz+Pr6YtCgQRgyZIhyMUp9pa3t4cOHAKB8AGX8YClUqBDMzc1hbGyMZcuWoWfPnmjbtq3ef7BmXG/Af9eyERF4e3ujcePGyn3g2c/F+Pj4KNfD0mdZ1WZsbAxvb294enrC398fI0eOxNq1azFt2jTMmzcPS5cuxaVLl/K45y+XsTYTExMkJiYCACZPnox+/fopwUf7Qers7IyyZcsCyPo6U/omY33a3+Zyd3dHSEgIPDw8sGLFCty9e1cJFNevX4etra3Oz1joq+ffTzJ+kdK+p1SpUgVeXl5YtmwZAP0P6FrPfw6kpqbC0tISvXr1gqWlpTIm1sLCAgBw4sQJFCxYEFZWVnnc8zeUJ/ulVObgwYPyww8/yI8//mhQP83x/FlzGQ87ZNwd3K1bN9FoNLJ58+ZM8/TVi2oTeXbmVZ06dWTx4sVibGwsq1evFpH8UZvWsmXLxN7eXnbu3JlbXXtrz9eWnJwsCQkJ0qpVK3FycpItW7Yo81JTUw3qEMXztWU31mT58uVSqFAhOXDgQG51LUdkdRZufHy8rFq1SkqVKiVFihSRXr16ySeffCKWlpY6P3Gh7160zWn/f/78ebG1tc12fKm+er427WHMe/fuSdmyZeWjjz6SjRs3yqRJk8TGxkY2btyYRz19ewxE79DzH56G8GEq8t8GfODAAalSpYpMmzYt0zyRZ/UsXbpUNBqNrFu3Tpmmz3W+am3r168XjUYjGo1GJwzlh9rOnDkjw4cPF3t7e1m7dq2I6P9r80W1iTwbHH/ixIlsH6/P9b2otoz9Pn36tAwePFhsbGyU9WYIXrbuUlNTJSwsTL744gtp06aN9OjRQzkRQJ/Xm8irb3MiIvfv35fatWtLaGhorvbxTb3sdZmYmCg//fSTVKtWTYoUKSK1a9dWQqy+r7fsmOT1Hqr8zBCO7WdFuzu3YsWKqFOnDrZs2QJHR0d0795dGVtjbGwMjUaDhIQEbNq0SbmEAKDfdb9qbcWLF0epUqUwbdo0tGjRIt/UJiJ48OAB4uPj8fPPPyMwMFDvD0kAL64NeHbxuhddwM5Q15v2cLWIICwsDFFRUVizZg2aNWum/6cw/7+XrTuNRgMXFxfMmDEDwH+XUzD012XG9xMAcHV1xfbt22FnZ5eXXX5lL3tdmpmZoXPnzmjTpg0ePHgAKysrFCpUyCDWW3Z4HSJ6oTt37mDgwIF48uQJPvjgAwwePBjAf9de0jKEwPC87GoDnl01Njw8XGcwa36pLTU1FQkJCbCxscl3tRm6F9WWkpKC+Ph42NnZGeR6A7KvTxscDLUu4MXrLmPIy0+1GWo92WEgope6ffs2pk2bhqNHj8LJyQlLliyBlZUVrK2tDX6DyKo2c3Nzg/kW9yJZ1WZhYQFbW9u87tpbe9Fr0tDl5/UGqG/dsTbDwUBEryQyMhLnz5/HqFGjkJKSAgsLC4wbNw6+vr46p5oaItZmmFib4crP9bE2w8VARK/t0KFDuHr1KjQaDTp37gxzc/O87lKOYW2GibUZrvxcH2szLAxE9MqePzxm6IfLMmJthom1Ga78XB9rM0yGcXUo0gv55UWfFdZmmFib4crP9bE2w8Q9RERERKR63ENEREREqsdARERERKrHQERERESqx0BEREREqsdARERERKrHQEREBqN+/foYOHDgO1v+uHHjULly5Xe2fCLSXwxEREQ5ZNmyZbC3t8/rbhDRG2AgIiIiItVjICIig5KamoqQkBDY2dmhcOHC+N///gft9WU1Gg02bdqk097e3h7Lli1T7t+9exedOnWCg4MDrKysUK1aNRw7dizL57px4wZKlCiBkJAQiAiSkpIwZMgQFClSBFZWVqhZsyb27dsHANi3bx969uyJqKgoaDQaaDQajBs37h38BYjoXTDJ6w4QEb2O5cuXo1evXvjrr79w4sQJ9O3bF8WKFUOfPn1e+tjY2FjUq1cPRYoUwebNm+Hi4oJTp04hPT09U9tz584hICAAvXr1wldffQUACAkJwaVLl7BmzRq4ublh48aNCAwMxPnz51G7dm3MmjULY8aMwdWrVwEA1tbWOVs8Eb0zDEREZFDc3d0xc+ZMaDQalC5dGufPn8fMmTNfKRCtXr0aDx8+xPHjx+Hg4AAA8Pb2ztTuyJEj+OCDDzBq1CgMHjwYAHD79m0sXboUt2/fhpubGwBgyJAh2LFjB5YuXYrJkyfDzs4OGo0GLi4uOVgxEeUGBiIiMii1atXS+YFJX19fTJ8+HWlpaS997JkzZ/Dee+8pYSgrt2/fRpMmTTBp0iSdM9rOnz+PtLQ0lCpVSqd9UlISChUq9PqFEJFeYSAionxDo9Hg+d+rTklJUf5vYWHx0mU4OjrCzc0NP//8Mz7++GPY2toCeHa4zdjYGCdPnoSxsbHOY3hojMjwcVA1ERmU5wdAHz16FCVLloSxsTEcHR0RFhamzLt27Rri4+OV+xUrVsSZM2fw5MmTbJdvYWGBrVu3wtzcHAEBAYiJiQEAvPfee0hLS8ODBw/g7e2tc9MeIjM1NX2lPVVEpH8YiIjIoNy+fRuDBg3C1atX8fPPP2P27Nn4/PPPAQANGzbEnDlzcPr0aZw4cQL9+vVDgQIFlMd26tQJLi4uaNWqFQ4fPox//vkHGzZsQGhoqM5zWFlZYdu2bTAxMUHTpk0RGxuLUqVKoUuXLggKCsKvv/6Kmzdv4q+//sKUKVOwbds2AICHhwdiY2OxZ88ePHr0SCeMEZF+YyAiIoMSFBSEhIQE1KhRA8HBwfj888/Rt29fAMD06dPh7u6OunXronPnzhgyZAgsLS2Vx5qammLnzp1wcnJCs2bN4OPjg6+//jrTITDg2WGw33//HSKC5s2bIy4uDkuXLkVQUBAGDx6M0qVLo1WrVjh+/DiKFSsGAKhduzb69euHDh06wNHREVOnTs2dPwoRvTWNPH/AnYiIiEhluIeIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhUj4GIiIiIVI+BiIiIiFSPgYiIiIhU7/8ArPMCYa627H8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = labeled.copy()\n",
        "bins = range(0, 100, 10)\n",
        "df['bucket'] = pd.cut(df['ZPPG_Performance'] * 100, bins=bins)\n",
        "bucket_histogram(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### sample down"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample(df, n=50):\n",
        "    grouped = df.groupby('bucket', observed=True)\n",
        "    samples = [group.sample(min(len(group), 50)) for _, group in grouped]\n",
        "    sampled = pd.concat(samples, ignore_index=True)\n",
        "    return sampled.drop(['bucket'], axis=1)\n",
        "\n",
        "sampled = sample(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampled_model = MLP().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=    0 loss.item()= 0.0012 error= 0.0438\n",
            "epoch=  200 loss.item()= 0.0013 error= 0.0437\n",
            "epoch=  400 loss.item()= 0.0012 error= 0.0438\n",
            "epoch=  600 loss.item()= 0.0011 error= 0.0437\n",
            "epoch=  800 loss.item()= 0.0012 error= 0.0438\n",
            "epoch= 1000 loss.item()= 0.0013 error= 0.0440\n",
            "epoch= 1200 loss.item()= 0.0013 error= 0.0438\n",
            "epoch= 1400 loss.item()= 0.0012 error= 0.0436\n",
            "epoch= 1600 loss.item()= 0.0013 error= 0.0432\n",
            "epoch= 1800 loss.item()= 0.0013 error= 0.0438\n",
            "epoch= 2000 loss.item()= 0.0013 error= 0.0439\n",
            "epoch= 2200 loss.item()= 0.0012 error= 0.0438\n",
            "epoch= 2400 loss.item()= 0.0011 error= 0.0439\n",
            "epoch= 2600 loss.item()= 0.0011 error= 0.0437\n",
            "epoch= 2800 loss.item()= 0.0013 error= 0.0441\n",
            "epoch= 3000 loss.item()= 0.0012 error= 0.0438\n",
            "epoch= 3200 loss.item()= 0.0013 error= 0.0439\n",
            "epoch= 3400 loss.item()= 0.0014 error= 0.0434\n",
            "epoch= 3600 loss.item()= 0.0015 error= 0.0439\n",
            "epoch= 3800 loss.item()= 0.0014 error= 0.0438\n",
            "epoch= 4000 loss.item()= 0.0012 error= 0.0441\n",
            "epoch= 4200 loss.item()= 0.0013 error= 0.0437\n",
            "epoch= 4400 loss.item()= 0.0011 error= 0.0436\n",
            "epoch= 4600 loss.item()= 0.0012 error= 0.0437\n",
            "epoch= 4800 loss.item()= 0.0012 error= 0.0438\n",
            "epoch= 5000 loss.item()= 0.0012 error= 0.0438\n",
            "epoch= 5200 loss.item()= 0.0013 error= 0.0437\n",
            "epoch= 5400 loss.item()= 0.0013 error= 0.0436\n",
            "epoch= 5600 loss.item()= 0.0012 error= 0.0441\n",
            "epoch= 5800 loss.item()= 0.0015 error= 0.0436\n",
            "epoch= 6000 loss.item()= 0.0012 error= 0.0434\n",
            "epoch= 6200 loss.item()= 0.0012 error= 0.0441\n",
            "epoch= 6400 loss.item()= 0.0012 error= 0.0440\n",
            "epoch= 6600 loss.item()= 0.0013 error= 0.0439\n",
            "epoch= 6800 loss.item()= 0.0013 error= 0.0439\n",
            "epoch= 7000 loss.item()= 0.0011 error= 0.0436\n",
            "epoch= 7200 loss.item()= 0.0012 error= 0.0436\n",
            "epoch= 7400 loss.item()= 0.0014 error= 0.0437\n",
            "epoch= 7600 loss.item()= 0.0011 error= 0.0438\n",
            "epoch= 7800 loss.item()= 0.0013 error= 0.0436\n",
            "epoch= 8000 loss.item()= 0.0013 error= 0.0434\n",
            "epoch= 8200 loss.item()= 0.0012 error= 0.0436\n",
            "epoch= 8400 loss.item()= 0.0013 error= 0.0440\n",
            "epoch= 8600 loss.item()= 0.0013 error= 0.0441\n",
            "epoch= 8800 loss.item()= 0.0011 error= 0.0437\n",
            "epoch= 9000 loss.item()= 0.0013 error= 0.0439\n",
            "epoch= 9200 loss.item()= 0.0015 error= 0.0441\n",
            "epoch= 9400 loss.item()= 0.0013 error= 0.0435\n",
            "epoch= 9600 loss.item()= 0.0012 error= 0.0441\n",
            "epoch= 9800 loss.item()= 0.0013 error= 0.0443\n",
            "epoch=10000 loss.item()= 0.0014 error= 0.0441\n",
            "epoch=10200 loss.item()= 0.0013 error= 0.0438\n",
            "epoch=10400 loss.item()= 0.0012 error= 0.0444\n",
            "epoch=10600 loss.item()= 0.0013 error= 0.0440\n",
            "epoch=10800 loss.item()= 0.0012 error= 0.0441\n",
            "epoch=11000 loss.item()= 0.0011 error= 0.0434\n",
            "epoch=11200 loss.item()= 0.0013 error= 0.0441\n",
            "epoch=11400 loss.item()= 0.0014 error= 0.0439\n",
            "epoch=11600 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=11800 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=12000 loss.item()= 0.0011 error= 0.0440\n",
            "epoch=12200 loss.item()= 0.0011 error= 0.0441\n",
            "epoch=12400 loss.item()= 0.0014 error= 0.0436\n",
            "epoch=12600 loss.item()= 0.0011 error= 0.0441\n",
            "epoch=12800 loss.item()= 0.0013 error= 0.0434\n",
            "epoch=13000 loss.item()= 0.0013 error= 0.0437\n",
            "epoch=13200 loss.item()= 0.0010 error= 0.0442\n",
            "epoch=13400 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=13600 loss.item()= 0.0013 error= 0.0438\n",
            "epoch=13800 loss.item()= 0.0013 error= 0.0440\n",
            "epoch=14000 loss.item()= 0.0014 error= 0.0442\n",
            "epoch=14200 loss.item()= 0.0011 error= 0.0441\n",
            "epoch=14400 loss.item()= 0.0012 error= 0.0442\n",
            "epoch=14600 loss.item()= 0.0012 error= 0.0443\n",
            "epoch=14800 loss.item()= 0.0011 error= 0.0438\n",
            "epoch=15000 loss.item()= 0.0011 error= 0.0437\n",
            "epoch=15200 loss.item()= 0.0012 error= 0.0439\n",
            "epoch=15400 loss.item()= 0.0013 error= 0.0440\n",
            "epoch=15600 loss.item()= 0.0011 error= 0.0437\n",
            "epoch=15800 loss.item()= 0.0012 error= 0.0440\n",
            "epoch=16000 loss.item()= 0.0012 error= 0.0438\n",
            "epoch=16200 loss.item()= 0.0014 error= 0.0439\n",
            "epoch=16400 loss.item()= 0.0014 error= 0.0440\n",
            "epoch=16600 loss.item()= 0.0012 error= 0.0444\n",
            "epoch=16800 loss.item()= 0.0015 error= 0.0442\n",
            "epoch=17000 loss.item()= 0.0012 error= 0.0438\n",
            "epoch=17200 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=17400 loss.item()= 0.0012 error= 0.0435\n",
            "epoch=17600 loss.item()= 0.0010 error= 0.0441\n",
            "epoch=17800 loss.item()= 0.0012 error= 0.0441\n",
            "epoch=18000 loss.item()= 0.0012 error= 0.0435\n",
            "epoch=18200 loss.item()= 0.0011 error= 0.0441\n",
            "epoch=18400 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=18600 loss.item()= 0.0013 error= 0.0436\n",
            "epoch=18800 loss.item()= 0.0015 error= 0.0435\n",
            "epoch=19000 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=19200 loss.item()= 0.0011 error= 0.0438\n",
            "epoch=19400 loss.item()= 0.0012 error= 0.0438\n",
            "epoch=19600 loss.item()= 0.0013 error= 0.0439\n",
            "epoch=19800 loss.item()= 0.0011 error= 0.0440\n",
            "epoch=20000 loss.item()= 0.0012 error= 0.0437\n",
            "epoch=20200 loss.item()= 0.0012 error= 0.0440\n",
            "epoch=20400 loss.item()= 0.0012 error= 0.0440\n",
            "epoch=20600 loss.item()= 0.0011 error= 0.0439\n",
            "epoch=20800 loss.item()= 0.0012 error= 0.0442\n",
            "epoch=21000 loss.item()= 0.0011 error= 0.0437\n",
            "epoch=21200 loss.item()= 0.0012 error= 0.0436\n",
            "epoch=21400 loss.item()= 0.0014 error= 0.0437\n",
            "epoch=21600 loss.item()= 0.0014 error= 0.0439\n",
            "epoch=21800 loss.item()= 0.0012 error= 0.0442\n",
            "epoch=22000 loss.item()= 0.0014 error= 0.0437\n",
            "epoch=22200 loss.item()= 0.0015 error= 0.0437\n",
            "epoch=22400 loss.item()= 0.0012 error= 0.0440\n",
            "epoch=22600 loss.item()= 0.0012 error= 0.0439\n",
            "epoch=22800 loss.item()= 0.0013 error= 0.0441\n",
            "epoch=23000 loss.item()= 0.0014 error= 0.0436\n",
            "epoch=23200 loss.item()= 0.0013 error= 0.0440\n",
            "epoch=23400 loss.item()= 0.0010 error= 0.0441\n",
            "epoch=23600 loss.item()= 0.0012 error= 0.0438\n",
            "epoch=23800 loss.item()= 0.0011 error= 0.0442\n",
            "epoch=24000 loss.item()= 0.0012 error= 0.0442\n",
            "epoch=24200 loss.item()= 0.0014 error= 0.0441\n",
            "epoch=24400 loss.item()= 0.0010 error= 0.0437\n",
            "epoch=24600 loss.item()= 0.0012 error= 0.0440\n",
            "epoch=24800 loss.item()= 0.0016 error= 0.0435\n",
            "epoch=25000 loss.item()= 0.0011 error= 0.0442\n",
            "epoch=25200 loss.item()= 0.0012 error= 0.0439\n",
            "epoch=25400 loss.item()= 0.0012 error= 0.0436\n",
            "epoch=25600 loss.item()= 0.0013 error= 0.0436\n",
            "epoch=25800 loss.item()= 0.0012 error= 0.0437\n",
            "epoch=26000 loss.item()= 0.0012 error= 0.0436\n",
            "epoch=26200 loss.item()= 0.0014 error= 0.0439\n",
            "epoch=26400 loss.item()= 0.0010 error= 0.0437\n",
            "epoch=26600 loss.item()= 0.0012 error= 0.0442\n",
            "epoch=26800 loss.item()= 0.0013 error= 0.0440\n",
            "epoch=27000 loss.item()= 0.0013 error= 0.0440\n",
            "epoch=27200 loss.item()= 0.0011 error= 0.0436\n",
            "epoch=27400 loss.item()= 0.0015 error= 0.0439\n",
            "epoch=27600 loss.item()= 0.0014 error= 0.0441\n",
            "epoch=27800 loss.item()= 0.0013 error= 0.0443\n",
            "epoch=28000 loss.item()= 0.0013 error= 0.0438\n",
            "epoch=28200 loss.item()= 0.0014 error= 0.0443\n",
            "epoch=28400 loss.item()= 0.0012 error= 0.0440\n",
            "epoch=28600 loss.item()= 0.0014 error= 0.0442\n",
            "epoch=28800 loss.item()= 0.0012 error= 0.0435\n",
            "epoch=29000 loss.item()= 0.0011 error= 0.0440\n",
            "epoch=29200 loss.item()= 0.0013 error= 0.0441\n",
            "epoch=29400 loss.item()= 0.0011 error= 0.0438\n",
            "epoch=29600 loss.item()= 0.0011 error= 0.0435\n",
            "epoch=29800 loss.item()= 0.0012 error= 0.0442\n"
          ]
        }
      ],
      "source": [
        "train(sampled_model, sampled, epochs=30000, lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.7847162485122681, 76804),\n",
              " (0.7804363369941711, 71793),\n",
              " (0.7791130542755127, 72376),\n",
              " (0.7736898064613342, 94408),\n",
              " (0.7723697423934937, 18369),\n",
              " (0.7723492383956909, 952),\n",
              " (0.7691422700881958, 7101),\n",
              " (0.7679545283317566, 88956),\n",
              " (0.7659670114517212, 58945),\n",
              " (0.765868604183197, 104260),\n",
              " (0.7655607461929321, 59917),\n",
              " (0.765295147895813, 479),\n",
              " (0.7651427984237671, 105607),\n",
              " (0.7650604248046875, 93762),\n",
              " (0.764275074005127, 81319)]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict solution\n",
        "topn(sampled_model, unlabeled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### sample up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upsample(df, n=2000):\n",
        "    grouped = df.groupby('bucket', observed=True)\n",
        "    samples = [(group if len(group) > n else group.sample(n, replace=True)) for _, group in grouped]\n",
        "    sampled = pd.concat(samples, ignore_index=True)\n",
        "    return sampled.drop(['bucket'], axis=1)\n",
        "\n",
        "upsampled = upsample(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "upsampled_model = MLP().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=    0 loss.item()= 0.0011 error= 0.0933\n",
            "epoch=  200 loss.item()= 0.0011 error= 0.0923\n",
            "epoch=  400 loss.item()= 0.0011 error= 0.0928\n",
            "epoch=  600 loss.item()= 0.0011 error= 0.0928\n",
            "epoch=  800 loss.item()= 0.0011 error= 0.0938\n",
            "epoch= 1000 loss.item()= 0.0011 error= 0.0925\n",
            "epoch= 1200 loss.item()= 0.0011 error= 0.0933\n",
            "epoch= 1400 loss.item()= 0.0011 error= 0.0922\n",
            "epoch= 1600 loss.item()= 0.0011 error= 0.0931\n",
            "epoch= 1800 loss.item()= 0.0011 error= 0.0934\n",
            "epoch= 2000 loss.item()= 0.0011 error= 0.0927\n",
            "epoch= 2200 loss.item()= 0.0011 error= 0.0925\n",
            "epoch= 2400 loss.item()= 0.0011 error= 0.0921\n",
            "epoch= 2600 loss.item()= 0.0011 error= 0.0928\n",
            "epoch= 2800 loss.item()= 0.0011 error= 0.0913\n",
            "epoch= 3000 loss.item()= 0.0011 error= 0.0926\n",
            "epoch= 3200 loss.item()= 0.0011 error= 0.0919\n",
            "epoch= 3400 loss.item()= 0.0011 error= 0.0921\n",
            "epoch= 3600 loss.item()= 0.0011 error= 0.0928\n",
            "epoch= 3800 loss.item()= 0.0011 error= 0.0924\n",
            "epoch= 4000 loss.item()= 0.0011 error= 0.0942\n",
            "epoch= 4200 loss.item()= 0.0011 error= 0.0934\n",
            "epoch= 4400 loss.item()= 0.0011 error= 0.0921\n",
            "epoch= 4600 loss.item()= 0.0011 error= 0.0919\n",
            "epoch= 4800 loss.item()= 0.0011 error= 0.0932\n",
            "epoch= 5000 loss.item()= 0.0011 error= 0.0926\n",
            "epoch= 5200 loss.item()= 0.0011 error= 0.0922\n",
            "epoch= 5400 loss.item()= 0.0011 error= 0.0936\n",
            "epoch= 5600 loss.item()= 0.0011 error= 0.0934\n",
            "epoch= 5800 loss.item()= 0.0011 error= 0.0931\n",
            "epoch= 6000 loss.item()= 0.0011 error= 0.0928\n",
            "epoch= 6200 loss.item()= 0.0011 error= 0.0931\n",
            "epoch= 6400 loss.item()= 0.0011 error= 0.0912\n",
            "epoch= 6600 loss.item()= 0.0011 error= 0.0929\n",
            "epoch= 6800 loss.item()= 0.0011 error= 0.0925\n",
            "epoch= 7000 loss.item()= 0.0011 error= 0.0923\n",
            "epoch= 7200 loss.item()= 0.0011 error= 0.0919\n",
            "epoch= 7400 loss.item()= 0.0011 error= 0.0924\n",
            "epoch= 7600 loss.item()= 0.0011 error= 0.0921\n",
            "epoch= 7800 loss.item()= 0.0011 error= 0.0943\n",
            "epoch= 8000 loss.item()= 0.0011 error= 0.0925\n",
            "epoch= 8200 loss.item()= 0.0011 error= 0.0921\n",
            "epoch= 8400 loss.item()= 0.0011 error= 0.0920\n",
            "epoch= 8600 loss.item()= 0.0011 error= 0.0912\n",
            "epoch= 8800 loss.item()= 0.0011 error= 0.0925\n",
            "epoch= 9000 loss.item()= 0.0011 error= 0.0931\n",
            "epoch= 9200 loss.item()= 0.0011 error= 0.0926\n",
            "epoch= 9400 loss.item()= 0.0011 error= 0.0922\n",
            "epoch= 9600 loss.item()= 0.0011 error= 0.0918\n",
            "epoch= 9800 loss.item()= 0.0011 error= 0.0930\n",
            "epoch=10000 loss.item()= 0.0011 error= 0.0933\n",
            "epoch=10200 loss.item()= 0.0011 error= 0.0924\n",
            "epoch=10400 loss.item()= 0.0011 error= 0.0925\n",
            "epoch=10600 loss.item()= 0.0011 error= 0.0917\n",
            "epoch=10800 loss.item()= 0.0011 error= 0.0911\n",
            "epoch=11000 loss.item()= 0.0011 error= 0.0933\n",
            "epoch=11200 loss.item()= 0.0011 error= 0.0925\n",
            "epoch=11400 loss.item()= 0.0011 error= 0.0926\n",
            "epoch=11600 loss.item()= 0.0011 error= 0.0934\n",
            "epoch=11800 loss.item()= 0.0011 error= 0.0940\n",
            "epoch=12000 loss.item()= 0.0011 error= 0.0932\n",
            "epoch=12200 loss.item()= 0.0011 error= 0.0920\n",
            "epoch=12400 loss.item()= 0.0011 error= 0.0937\n",
            "epoch=12600 loss.item()= 0.0011 error= 0.0921\n",
            "epoch=12800 loss.item()= 0.0011 error= 0.0928\n",
            "epoch=13000 loss.item()= 0.0011 error= 0.0928\n",
            "epoch=13200 loss.item()= 0.0011 error= 0.0923\n",
            "epoch=13400 loss.item()= 0.0011 error= 0.0930\n",
            "epoch=13600 loss.item()= 0.0011 error= 0.0934\n",
            "epoch=13800 loss.item()= 0.0011 error= 0.0938\n",
            "epoch=14000 loss.item()= 0.0011 error= 0.0932\n",
            "epoch=14200 loss.item()= 0.0011 error= 0.0928\n",
            "epoch=14400 loss.item()= 0.0011 error= 0.0921\n",
            "epoch=14600 loss.item()= 0.0011 error= 0.0933\n",
            "epoch=14800 loss.item()= 0.0011 error= 0.0941\n",
            "epoch=15000 loss.item()= 0.0011 error= 0.0940\n",
            "epoch=15200 loss.item()= 0.0011 error= 0.0926\n",
            "epoch=15400 loss.item()= 0.0011 error= 0.0931\n",
            "epoch=15600 loss.item()= 0.0011 error= 0.0934\n",
            "epoch=15800 loss.item()= 0.0011 error= 0.0934\n",
            "epoch=16000 loss.item()= 0.0011 error= 0.0934\n",
            "epoch=16200 loss.item()= 0.0011 error= 0.0932\n",
            "epoch=16400 loss.item()= 0.0011 error= 0.0929\n",
            "epoch=16600 loss.item()= 0.0011 error= 0.0927\n",
            "epoch=16800 loss.item()= 0.0011 error= 0.0933\n",
            "epoch=17000 loss.item()= 0.0010 error= 0.0939\n",
            "epoch=17200 loss.item()= 0.0011 error= 0.0927\n",
            "epoch=17400 loss.item()= 0.0011 error= 0.0922\n",
            "epoch=17600 loss.item()= 0.0011 error= 0.0936\n",
            "epoch=17800 loss.item()= 0.0011 error= 0.0930\n",
            "epoch=18000 loss.item()= 0.0011 error= 0.0937\n",
            "epoch=18200 loss.item()= 0.0011 error= 0.0943\n",
            "epoch=18400 loss.item()= 0.0010 error= 0.0941\n",
            "epoch=18600 loss.item()= 0.0011 error= 0.0939\n",
            "epoch=18800 loss.item()= 0.0011 error= 0.0930\n",
            "epoch=19000 loss.item()= 0.0011 error= 0.0921\n",
            "epoch=19200 loss.item()= 0.0011 error= 0.0930\n",
            "epoch=19400 loss.item()= 0.0011 error= 0.0919\n",
            "epoch=19600 loss.item()= 0.0011 error= 0.0936\n",
            "epoch=19800 loss.item()= 0.0011 error= 0.0923\n"
          ]
        }
      ],
      "source": [
        "train(upsampled_model, upsampled, epochs=20000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.6616739630699158, 23565),\n",
              " (0.650332510471344, 16423),\n",
              " (0.649997353553772, 96286),\n",
              " (0.6470462679862976, 8415),\n",
              " (0.6463005542755127, 106276),\n",
              " (0.6435211896896362, 93762),\n",
              " (0.6419152021408081, 110080),\n",
              " (0.6417442560195923, 7101),\n",
              " (0.6394185423851013, 87620),\n",
              " (0.6392368078231812, 52609),\n",
              " (0.6378263235092163, 18123),\n",
              " (0.6370429992675781, 107278),\n",
              " (0.6351938247680664, 58945),\n",
              " (0.6351312398910522, 10265),\n",
              " (0.6350407600402832, 34438)]"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict solution\n",
        "topn(upsampled_model, unlabeled)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_hf_nlp",
      "language": "python",
      "name": "venv_hf_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
