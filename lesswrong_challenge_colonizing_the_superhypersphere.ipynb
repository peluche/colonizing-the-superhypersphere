{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8n_vM3jIitW"
      },
      "source": [
        "# lesswrong challenge: Colonizing the SuperHyperSphere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3fu4tcIgHF"
      },
      "source": [
        "problem: https://www.lesswrong.com/posts/Rpjrwspx2QZuHbmPE/d-and-d-sci-fi-colonizing-the-superhypersphere-evaluation\n",
        "\n",
        "submit: https://h-b-p.github.io/d-and-d-sci-SuperHyperSphere/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aktjQ_0E0BWR"
      },
      "source": [
        "## setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOkR7Lp1B_6b",
        "outputId": "acc75e28-97a4-4b55-f703-703fc4e8c5bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/sfgeekgit/lesswrongDataDzppg/main/cleared_sites_formated.csv\n",
        "!wget https://raw.githubusercontent.com/sfgeekgit/lesswrongDataDzppg/main/measured_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "82HUMHLYzpwS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KQTuTq9u_WBQ"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "unlabeled = pd.read_csv('cleared_sites_formated.csv')\n",
        "labeled = pd.read_csv('measured_data.csv')\n",
        "n_features = labeled.shape[1] - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKtElfWrAiqi",
        "outputId": "d5b29791-b579-4255-ac9e-f88c555a8e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data: 9366\n",
            "test data:  1041\n"
          ]
        }
      ],
      "source": [
        "# split into training and test sets\n",
        "train_data2, test_data = train_test_split(labeled, test_size =.1, random_state = 1)\n",
        "train_labels = train_data2['ZPPG_Performance']\n",
        "train_data = train_data2.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "\n",
        "print(f'train data: {len(train_data)}')\n",
        "print(f'test data:  {len(test_data)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RtIRD5cz948"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4_e6yDO-PVLk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, dataset):\n",
        "  model.eval()\n",
        "  val = dataset.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "  preds = model(torch.tensor(val.values).float().to(device))\n",
        "  labels = torch.tensor(dataset['ZPPG_Performance'].values).view(-1, 1).to(device)\n",
        "  diff = preds.detach() - labels\n",
        "  error = diff.abs().mean().item()\n",
        "  model.train()\n",
        "  return error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "90VqjJY46_3T"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def topn(model, dataset, n=15):\n",
        "  model.eval()\n",
        "  to_drop = ['ZPPG_id']\n",
        "  if 'ZPPG_Performance' in dataset: to_drop.append('ZPPG_Performance')\n",
        "  preds = model(torch.tensor(dataset.drop(to_drop, axis=1).values).float().to(device))\n",
        "  ids = dataset['ZPPG_id']\n",
        "  preds_id = list(zip(\n",
        "    preds.view(-1).tolist(),\n",
        "    ids.values.tolist()))\n",
        "  return sorted(preds_id, reverse=True)[:n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PS_EWz00EXo"
      },
      "source": [
        "## model and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eWGrZfBgAjlJ"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, n_inputs=n_features, hidden=32, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(n_inputs, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, hidden),\n",
        "        nn.BatchNorm1d(hidden),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden, 1),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    output = self.model(x)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6ba5xzovGe0u"
      },
      "outputs": [],
      "source": [
        "model = MLP().to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAdJbaa_AuQ-",
        "outputId": "9180ac60-273b-4a86-d04b-6e0fca155b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch=    0 loss.item()= 0.2113 error_test= 0.2487 error_train= 0.2487\n",
            "epoch=  200 loss.item()= 0.0492 error_test= 0.1356 error_train= 0.1356\n",
            "epoch=  400 loss.item()= 0.0350 error_test= 0.1344 error_train= 0.1344\n",
            "epoch=  600 loss.item()= 0.0324 error_test= 0.1327 error_train= 0.1327\n",
            "epoch=  800 loss.item()= 0.0302 error_test= 0.1309 error_train= 0.1309\n",
            "epoch= 1000 loss.item()= 0.0292 error_test= 0.1304 error_train= 0.1304\n",
            "epoch= 1200 loss.item()= 0.0290 error_test= 0.1299 error_train= 0.1299\n",
            "epoch= 1400 loss.item()= 0.0282 error_test= 0.1294 error_train= 0.1294\n",
            "epoch= 1600 loss.item()= 0.0277 error_test= 0.1278 error_train= 0.1278\n",
            "epoch= 1800 loss.item()= 0.0201 error_test= 0.0956 error_train= 0.0956\n",
            "epoch= 2000 loss.item()= 0.0142 error_test= 0.0714 error_train= 0.0714\n",
            "epoch= 2200 loss.item()= 0.0115 error_test= 0.0636 error_train= 0.0636\n",
            "epoch= 2400 loss.item()= 0.0098 error_test= 0.0597 error_train= 0.0597\n",
            "epoch= 2600 loss.item()= 0.0090 error_test= 0.0590 error_train= 0.0590\n",
            "epoch= 2800 loss.item()= 0.0083 error_test= 0.0587 error_train= 0.0587\n",
            "epoch= 3000 loss.item()= 0.0079 error_test= 0.0579 error_train= 0.0579\n",
            "epoch= 3200 loss.item()= 0.0070 error_test= 0.0571 error_train= 0.0571\n",
            "epoch= 3400 loss.item()= 0.0068 error_test= 0.0578 error_train= 0.0578\n",
            "epoch= 3600 loss.item()= 0.0067 error_test= 0.0574 error_train= 0.0574\n",
            "epoch= 3800 loss.item()= 0.0065 error_test= 0.0571 error_train= 0.0571\n",
            "epoch= 4000 loss.item()= 0.0062 error_test= 0.0569 error_train= 0.0569\n",
            "epoch= 4200 loss.item()= 0.0056 error_test= 0.0545 error_train= 0.0545\n",
            "epoch= 4400 loss.item()= 0.0052 error_test= 0.0532 error_train= 0.0532\n",
            "epoch= 4600 loss.item()= 0.0047 error_test= 0.0527 error_train= 0.0527\n",
            "epoch= 4800 loss.item()= 0.0046 error_test= 0.0536 error_train= 0.0536\n",
            "epoch= 5000 loss.item()= 0.0046 error_test= 0.0534 error_train= 0.0534\n",
            "epoch= 5200 loss.item()= 0.0044 error_test= 0.0532 error_train= 0.0532\n",
            "epoch= 5400 loss.item()= 0.0043 error_test= 0.0526 error_train= 0.0526\n",
            "epoch= 5600 loss.item()= 0.0040 error_test= 0.0528 error_train= 0.0528\n",
            "epoch= 5800 loss.item()= 0.0041 error_test= 0.0530 error_train= 0.0530\n",
            "epoch= 6000 loss.item()= 0.0040 error_test= 0.0525 error_train= 0.0525\n",
            "epoch= 6200 loss.item()= 0.0037 error_test= 0.0516 error_train= 0.0516\n",
            "epoch= 6400 loss.item()= 0.0036 error_test= 0.0507 error_train= 0.0507\n",
            "epoch= 6600 loss.item()= 0.0034 error_test= 0.0520 error_train= 0.0520\n",
            "epoch= 6800 loss.item()= 0.0033 error_test= 0.0510 error_train= 0.0510\n",
            "epoch= 7000 loss.item()= 0.0030 error_test= 0.0515 error_train= 0.0515\n",
            "epoch= 7200 loss.item()= 0.0030 error_test= 0.0504 error_train= 0.0504\n",
            "epoch= 7400 loss.item()= 0.0029 error_test= 0.0525 error_train= 0.0525\n",
            "epoch= 7600 loss.item()= 0.0028 error_test= 0.0509 error_train= 0.0509\n",
            "epoch= 7800 loss.item()= 0.0027 error_test= 0.0525 error_train= 0.0525\n",
            "epoch= 8000 loss.item()= 0.0027 error_test= 0.0520 error_train= 0.0520\n",
            "epoch= 8200 loss.item()= 0.0028 error_test= 0.0519 error_train= 0.0519\n",
            "epoch= 8400 loss.item()= 0.0026 error_test= 0.0524 error_train= 0.0524\n",
            "epoch= 8600 loss.item()= 0.0027 error_test= 0.0533 error_train= 0.0533\n",
            "epoch= 8800 loss.item()= 0.0027 error_test= 0.0516 error_train= 0.0516\n",
            "epoch= 9000 loss.item()= 0.0025 error_test= 0.0523 error_train= 0.0523\n",
            "epoch= 9200 loss.item()= 0.0025 error_test= 0.0514 error_train= 0.0514\n",
            "epoch= 9400 loss.item()= 0.0025 error_test= 0.0517 error_train= 0.0517\n",
            "epoch= 9600 loss.item()= 0.0023 error_test= 0.0531 error_train= 0.0531\n",
            "epoch= 9800 loss.item()= 0.0024 error_test= 0.0522 error_train= 0.0522\n"
          ]
        }
      ],
      "source": [
        "def train(model, epochs=10000):\n",
        "  model.train()\n",
        "  labels = torch.tensor(labeled['ZPPG_Performance'].values).float().view(-1, 1).to(device)\n",
        "  data = labeled.drop(['ZPPG_id', 'ZPPG_Performance'], axis=1)\n",
        "  data = torch.tensor(data.values).float().to(device)\n",
        "  # data = torch.tensor(train_data.values).float().to(device)\n",
        "  # labels = torch.tensor(train_labels.values).float().view(-1, 1).to(device)\n",
        "  for epoch in range(epochs):\n",
        "    predictions = model(data)\n",
        "    loss = F.mse_loss(predictions, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 200 == 0:\n",
        "      error_test = error_train = evaluate(model, labeled)\n",
        "      # error_test = evaluate(model, test_data)\n",
        "      # error_train = evaluate(model, train_data2)\n",
        "      print(f'{epoch=:5} {loss.item()=:7.4f} {error_test=:7.4f} {error_train=:7.4f}')\n",
        "  model.eval()\n",
        "\n",
        "train(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nDTgt3p0Jgm"
      },
      "source": [
        "## eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLl-ai-v1uMU",
        "outputId": "12d8182e-9fde-47b9-83b3-ebba0640113c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0.5654187798500061, 58945),\n",
              " (0.5511074662208557, 95686),\n",
              " (0.5473467707633972, 43689),\n",
              " (0.5465434789657593, 71793),\n",
              " (0.5456352233886719, 14132),\n",
              " (0.5442185997962952, 9344),\n",
              " (0.5426499247550964, 104703),\n",
              " (0.5410141348838806, 9599),\n",
              " (0.5369860529899597, 50035),\n",
              " (0.5354612469673157, 63388),\n",
              " (0.5349441766738892, 104260),\n",
              " (0.532487154006958, 100838),\n",
              " (0.5323276519775391, 58152),\n",
              " (0.5320469737052917, 73353),\n",
              " (0.5319209694862366, 952)]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predict solution\n",
        "topn(model, unlabeled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqh4i9be19PY",
        "outputId": "81646972-c4e3-4ce9-ab81-7afee8518e6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1.8702857494354248, 3412),\n",
              " (1.8266371488571167, 2695),\n",
              " (1.8240541219711304, 7487),\n",
              " (1.8221070766448975, 2509),\n",
              " (1.821927547454834, 3773),\n",
              " (1.8169137239456177, 8721),\n",
              " (1.8135265111923218, 5386),\n",
              " (1.8075464963912964, 5751),\n",
              " (1.8061460256576538, 7243),\n",
              " (1.7997924089431763, 2004),\n",
              " (1.797755241394043, 5072),\n",
              " (1.7943958044052124, 4148),\n",
              " (1.7933684587478638, 6989),\n",
              " (1.791631817817688, 7146),\n",
              " (1.7850587368011475, 5667)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validation\n",
        "topn(model, test_data)\n",
        "topn(model, train_data2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_hf_nlp",
      "language": "python",
      "name": "venv_hf_nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
